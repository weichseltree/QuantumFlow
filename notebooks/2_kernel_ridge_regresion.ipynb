{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup notebook if it is run on Google Colab, cwd = notebook file location\n",
    "try:\n",
    "    # change notebook_path if this notebook is in a different subfolder of Google Drive\n",
    "    notebook_path = \"Projects/QuantumFlow/notebooks\"\n",
    "\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/\" + notebook_path)\n",
    "\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q ruamel.yaml\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# setup paths and variables for shared code (../quantumflow) and data (../data)\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# import shared code, must run 0_create_shared_project_files.ipynb first!\n",
    "from quantumflow.utils import load_hyperparameters, QFDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Kernel Ridge Regression\n",
    "###Paper:\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = \\not{\\bar{T}}\\sum_{j=1}^{M}\\alpha_j k(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$k(\\mathbf{n}, \\mathbf{n}') = \\text{exp}(-\\| \\mathbf{n} - \\mathbf{n}'\\|^2/(2\\sigma^2))$$\n",
    "\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\alpha}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\lambda \\|\\alpha\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "### Sklearn:\n",
    "\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = 1\\sum_{j=1}^{M}\\omega_j \\tilde{k}(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$\\tilde{k}(\\mathbf{n}, \\mathbf{n}') =  \\text{exp}(-\\gamma~\\| \\mathbf{n} - \\mathbf{n}'\\|^2)$$\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\omega}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\tilde{\\alpha} \\|\\omega\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\\omega = \\bar{T} \\alpha$$\n",
    "$$\\gamma = \\frac{1}{2\\sigma^2}$$\n",
    "$$\\tilde{\\alpha} = \\frac{1}{\\not{\\bar{T}}^2} \\lambda$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRRKineticEnergyFunctional(tf.Module):\n",
    "\n",
    "    def __init__(self, X_train, y_train, m, l, alpha=None, lambda_=None, gamma=None, sigma=None):\n",
    "        super(KRRKineticEnergyFunctional, self).__init__()\n",
    "        from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = lambda_\n",
    "        if gamma is None:\n",
    "            gamma = 1/(2*sigma**2)\n",
    "\n",
    "        model = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        self.X_train = tf.Variable(initial_value=X_train)\n",
    "        self.weights = tf.Variable(initial_value=model.dual_coef_)\n",
    "        self.gamma = tf.Variable(initial_value=gamma, dtype=self.X_train.dtype)\n",
    "        self.m = tf.Variable(initial_value=m)\n",
    "        self.l = tf.Variable(initial_value=l)\n",
    "\n",
    "    def rbf_kernel(self, X):\n",
    "        return tf.exp(-self.gamma*tf.reduce_sum(tf.square(tf.expand_dims(X, axis=2) - tf.expand_dims(tf.transpose(self.X_train), axis=0)), axis=1))\n",
    "\n",
    "    def derivative(self, X):\n",
    "        h = 1/(self.X_train.shape[1]-1)\n",
    "        return -1/h*tf.reduce_sum(tf.expand_dims(self.weights, axis=0)*2*self.gamma* \\\n",
    "                                 (tf.expand_dims(X, axis=2) - tf.expand_dims(tf.transpose(self.X_train), axis=0))* \\\n",
    "                                  tf.expand_dims(self.rbf_kernel(X), axis=1), axis=2)\n",
    " \n",
    "    def kinetic_energy(self, kernel):\n",
    "        return tf.reduce_sum(tf.expand_dims(self.weights, axis=0)*kernel, axis=1, name='kinetic_energy')\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, X):\n",
    "        return {'kinetic_energy': self.kinetic_energy(self.rbf_kernel(X))}\n",
    "\n",
    "    @tf.function\n",
    "    def projection_subspace(self, X):\n",
    "        metric = tf.reduce_sum(tf.square(tf.expand_dims(X, axis=2) - tf.expand_dims(tf.transpose(self.X_train), axis=0)), axis=1)\n",
    "        _, closest_indices = tf.math.top_k(-metric, k=self.m)\n",
    "        X_closest = tf.gather(self.X_train, closest_indices)\n",
    "\n",
    "        X_diff = tf.expand_dims(X, axis=1) - X_closest\n",
    "        C = tf.linalg.matmul(X_diff, X_diff, transpose_a=True)/tf.cast(self.m, X.dtype)\n",
    "\n",
    "        eigen_vals, eigen_vecs = tf.linalg.eigh(C)\n",
    "        return eigen_vecs[:, :, -self.l:]\n",
    "\n",
    "    @tf.function\n",
    "    def projection_matrix(self, X):\n",
    "        largest_eigen_vecs = self.projection_subspace(X)\n",
    "        return tf.linalg.matmul(largest_eigen_vecs, largest_eigen_vecs, transpose_b=True)\n",
    "\n",
    "    @tf.function\n",
    "    def project(self, X, functional_derivative):\n",
    "        projection_subspace = self.projection_subspace(X)\n",
    "        return tf.reduce_sum(tf.linalg.matmul(projection_subspace, tf.linalg.matmul(projection_subspace, tf.expand_dims(functional_derivative, axis=2), transpose_a=True)), axis=-1)\n",
    "\n",
    "    def signatures(self, dataset_train):\n",
    "        return {'serving_default': self.__call__.get_concrete_function(tf.TensorSpec([None, dataset_train.discretisation_points], dataset_train.dtype, name='density')),\n",
    "                'projection_subspace': self.projection_subspace.get_concrete_function(tf.TensorSpec([None, dataset_train.discretisation_points], dataset_train.dtype, name='density')),\n",
    "                'projection_matrix': self.projection_matrix.get_concrete_function(tf.TensorSpec([None, dataset_train.discretisation_points], dataset_train.dtype, name='density')),\n",
    "                'project': self.project.get_concrete_function(tf.TensorSpec([None, dataset_train.discretisation_points], dataset_train.dtype, name='density'),\n",
    "                                                              tf.TensorSpec([None, dataset_train.discretisation_points], dataset_train.dtype, name='functional_derivative'))\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "experiment = 'ke_krr'\n",
    "\n",
    "base_dir = os.path.join(data_dir, experiment)\n",
    "if not os.path.exists(base_dir): os.makedirs(base_dir)\n",
    "file_hyperparams = os.path.join(base_dir, \"hyperparams.config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $file_hyperparams\n",
    "\n",
    "default: &DEFAULT\n",
    "    run_name: default\n",
    "    dataset_train: recreate/dataset_paper.hdf5\n",
    "    dataset_test: recreate/dataset_test.hdf5\n",
    "    dtype: float64\n",
    "    predict_batch_size: 100\n",
    "    N: 1\n",
    "\n",
    "    features: ['density']\n",
    "    targets: ['kinetic_energy']\n",
    "    von_weizsaecker_split: False\n",
    "\n",
    "    model_kwargs:\n",
    "        lambda_: 12.0E-14\n",
    "        sigma: 43\n",
    "        m: 30\n",
    "        l: 5\n",
    "\n",
    "allN: &ALLN\n",
    "    <<: *DEFAULT\n",
    "    N: all\n",
    "    model_kwargs:\n",
    "        lambda_: 3.2E-14\n",
    "        sigma: 47\n",
    "        m: 30\n",
    "        l: 5\n",
    "\n",
    "vW: \n",
    "    <<: *DEFAULT\n",
    "    N: 2\n",
    "    von_weizsaecker_split: True\n",
    "\n",
    "vW_allN: \n",
    "    <<: *DEFAULT\n",
    "    N: all\n",
    "    von_weizsaecker_split: True\n",
    "    von_weizsaecker_factor: 0.01\n",
    "    model_kwargs:\n",
    "        lambda_: 3.2E-14\n",
    "        sigma: 47\n",
    "        m: 30\n",
    "        l: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'default'\n",
    "params = load_hyperparameters(file_hyperparams, run_name=run_name)\n",
    "\n",
    "dataset_train = QFDataset(os.path.join(data_dir, params['dataset_train']), params)\n",
    "\n",
    "model = KRRKineticEnergyFunctional(X_train=dataset_train.density, y_train=dataset_train.kinetic_energy, **params['model_kwargs'])\n",
    "\n",
    "params['export_dir'] = os.path.join(data_dir, experiment, run_name, 'saved_model')\n",
    "if not os.path.exists(params['export_dir']): os.makedirs(params['export_dir'])\n",
    "tf.saved_model.save(model, params['export_dir'], signatures=model.signatures(dataset_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "figsize = (20, 3)\n",
    "dpi = None\n",
    "\n",
    "dataset_test = QFDataset(os.path.join(data_dir, params['dataset_test']), params)\n",
    "dataset_sample = QFDataset(os.path.join(data_dir, 'recreate/dataset_sample.hdf5'), params)\n",
    "\n",
    "y_predict = tf.concat([model(dataset_test.density[i*params['predict_batch_size']:(i+1)*params['predict_batch_size']])['kinetic_energy'] for i in range(len(dataset_test.density)//params['predict_batch_size'])], axis=0)\n",
    "absolute_error = np.abs(y_predict - dataset_test.kinetic_energy)\n",
    "MAE = np.mean(absolute_error)\n",
    "ae_std = np.std(absolute_error)\n",
    "ae_max = np.max(absolute_error)\n",
    "\n",
    "kcalmol_per_hartree = 627.51\n",
    "\n",
    "print(\"MAE:\", MAE*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"std:\", ae_std*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"max:\", ae_max*kcalmol_per_hartree, \"kcal/mol\")\n",
    "\n",
    "print(\"\\nrelative error:\", np.mean(absolute_error/dataset_test.kinetic_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "paper_weights = 10**7*pd.read_csv('1b_paper_potentials.txt', delimiter=' ')['αj'].values\n",
    "\n",
    "print('Kernel Ridge: ', model.weights.numpy()[:4], '...')\n",
    "print('Paper Weights:', paper_weights[:4], '...')\n",
    "\n",
    "print('Deviation:', np.mean(np.abs(model.weights.numpy() - paper_weights)/np.abs(paper_weights)))\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.hist(model.weights.numpy(), bins=100, label=\"weights\")\n",
    "plt.hist(model.weights.numpy() - paper_weights, bins=50, label=\"error\")\n",
    "#plt.title(\"Distribution of weights\")\n",
    "plt.xlabel('α parameters')\n",
    "plt.ylabel('count')\n",
    "plt.ylim([0, 10])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functional derivative\n",
    "\n",
    "$$ \\frac{1}{\\Delta x} \\nabla T^\\text{ML}(\\mathbf{n}) = \\bar{T}\\sum_{j=1}^{M}\\alpha_j'(\\mathbf{n}_j - \\mathbf{n})k(\\mathbf{n}_j, \\mathbf{n}) = -\\frac{1}{h} \\sum_{j=1}^{M}\\omega_j \\gamma 2(\\mathbf{n} - \\mathbf{n}_j)k(\\mathbf{n}_j, \\mathbf{n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_derivative = model.derivative(dataset_sample.density)\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.plot(dataset_sample.x, tf.transpose(prediction_derivative), 'r', label='MLA')\n",
    "plt.plot(dataset_sample.x, tf.transpose(dataset_sample.derivative), '--k', label='Exact')\n",
    "plt.ylim([-40, 40])\n",
    "plt.grid(True)\n",
    "plt.xlabel('x / bohr')\n",
    "plt.ylabel('functional derivative')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_derivative_proj = model.project(dataset_sample.density, prediction_derivative)\n",
    "derivative_proj =  model.project(dataset_sample.density, dataset_sample.derivative)\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.plot(dataset_sample.x, tf.transpose(prediction_derivative_proj), 'r', label=\"MLA\")\n",
    "plt.plot(dataset_sample.x, tf.transpose(derivative_proj), '--k', label='Exact (projected functional derivative)')\n",
    "plt.plot(dataset_sample.x, tf.transpose(dataset_sample.derivative), '--g', label='Actual functional derivative')\n",
    "plt.ylim([-10, 25])\n",
    "plt.xlabel('x / bohr')\n",
    "plt.ylabel('functional derivative')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset_train.density\n",
    "X = dataset_sample.potential\n",
    "m = 30\n",
    "l = 5\n",
    "\n",
    "metric = tf.reduce_sum(tf.square(tf.expand_dims(X, axis=2) - tf.expand_dims(tf.transpose(X_train), axis=0)), axis=1)\n",
    "_, closest_indices = tf.math.top_k(-metric, k=m)\n",
    "X_closest = tf.gather(X_train, closest_indices)\n",
    "\n",
    "X_diff = tf.expand_dims(X, axis=1) - X_closest\n",
    "C = tf.linalg.matmul(X_diff, X_diff, transpose_a=True)/tf.cast(m, X.dtype)\n",
    "\n",
    "eigen_vals, eigen_vecs = tf.linalg.eigh(C)\n",
    "largest_eigen_vecs = eigen_vecs[:, :, -l:]\n",
    "\n",
    "P_ml = tf.linalg.matmul(largest_eigen_vecs, largest_eigen_vecs, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_proj = tf.linalg.matvec(P_ml, dataset_sample.potential)\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.plot(dataset_sample.x, largest_eigen_vecs[0])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.plot(dataset_sample.x, tf.transpose(potential_proj))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMD1rIOSwhmA+lrA5VPu2BF",
   "collapsed_sections": [],
   "name": "2_kernel_ridge_regresion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
