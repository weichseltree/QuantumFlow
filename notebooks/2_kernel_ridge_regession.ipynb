{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"Projects/QuantumFlow/notebooks\"\n",
    "try:\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/\" + notebook_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from quantumflow.colab_train_utils import load_hyperparameters, test_colab_devices, unpack_dataset\n",
    "from quantumflow.calculus_utils import integrate_simpson, normalize, predict, functional_derivative\n",
    "\n",
    "!pip install -q ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "experiment = 'krr'\n",
    "run_name = 'default'\n",
    "base_dir = os.path.join(data_dir, experiment)\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, experiment)): os.makedirs(os.path.join(data_dir, experiment))\n",
    "file_hyperparams = os.path.join(data_dir, experiment, \"hyperparams.config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $file_hyperparams\n",
    "\n",
    "default: &DEFAULT\n",
    "    run_name: default\n",
    "    dataset_train: recreate_paper\n",
    "    dataset_val: recreate\n",
    "    N: 1\n",
    "\n",
    "    lambda_coeff: 12.0E-14\n",
    "    sigma: 43\n",
    "    m: 30\n",
    "    l: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_hyperparameters(file_hyperparams, run_name=run_name)\n",
    "\n",
    "with open(os.path.join(data_dir, params['dataset_train'], 'dataset_training.pkl'), 'rb') as f:\n",
    "    x, potentials, wavefunctions, energies, densities, kenergies, M, G, h = unpack_dataset(params['N'], pickle.load(f))\n",
    "    \n",
    "with open(os.path.join(data_dir, params['dataset_val'], 'dataset_testing.pkl'), 'rb') as f:\n",
    "    _, test_potentials, _, _, test_densities, test_kenergies, M_test, _, _ = unpack_dataset(params['N'], pickle.load(f))\n",
    "\n",
    "X_train = densities\n",
    "X_test = test_densities\n",
    "\n",
    "y_train = kenergies\n",
    "y_test = test_kenergies\n",
    "\n",
    "T_mean = np.mean(y_train)\n",
    "\n",
    "print(\"T_mean:\", T_mean)\n",
    "print(\"lambda:\", params['lambda_coeff'])\n",
    "print(\"sigma:\", params['sigma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Kernel Ridge Regression\n",
    "###Paper:\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = \\not{\\bar{T}}\\sum_{j=1}^{M}\\alpha_j k(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$k(\\mathbf{n}, \\mathbf{n}') = \\text{exp}(-\\| \\mathbf{n} - \\mathbf{n}'\\|^2/(2\\sigma^2))$$\n",
    "\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\alpha}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\lambda \\|\\alpha\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "### Sklearn:\n",
    "\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = 1\\sum_{j=1}^{M}\\omega_j \\tilde{k}(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$\\tilde{k}(\\mathbf{n}, \\mathbf{n}') =  \\text{exp}(-\\gamma~\\| \\mathbf{n} - \\mathbf{n}'\\|^2)$$\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\omega}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\tilde{\\alpha} \\|\\omega\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\\omega = \\bar{T} \\alpha$$\n",
    "$$\\gamma = \\frac{1}{2\\sigma^2}$$\n",
    "$$\\tilde{\\alpha} = \\frac{1}{\\not{\\bar{T}}^2} \\lambda$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "alpha = params['lambda_coeff']#/(T_mean**2)\n",
    "gamma = 1/(2*params['sigma']**2)\n",
    "\n",
    "clf = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "absolute_error = np.abs(y_predict - y_test)\n",
    "MAE = np.mean(absolute_error)\n",
    "ae_std = np.std(absolute_error)\n",
    "ae_max = np.max(absolute_error)\n",
    "\n",
    "kcalmol_per_hartree = 627.51\n",
    "\n",
    "print(\"MAE:\", MAE*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"std:\", ae_std*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"max:\", ae_max*kcalmol_per_hartree, \"kcal/mol\")\n",
    "\n",
    "print(\"\\nrelative error:\", np.mean(absolute_error/y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "paper_weights = 10**7*pd.read_csv('1b_paper_potentials.txt', delimiter=' ')['αj'].values\n",
    "weights = clf.dual_coef_\n",
    "\n",
    "print('Kernel Ridge: ', weights[:4], '...')\n",
    "print('Paper Weights:', paper_weights[:4], '...')\n",
    "\n",
    "plt.figure(figsize=(10, 2), dpi=200)\n",
    "plt.hist(weights, bins=100, label=\"weights\")\n",
    "#plt.title(\"Distribution of weights\")\n",
    "plt.xlabel('α parameters')\n",
    "plt.ylabel('count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, experiment, run_name + '.pkl'), 'wb') as f:\n",
    "    pickle.dump({'X_train': X_train, 'weights': weights}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functional derivative\n",
    "\n",
    "$$ \\frac{1}{\\Delta x} \\nabla T^\\text{ML}(\\mathbf{n}) = \\bar{T}\\sum_{j=1}^{M}\\alpha_j'(\\mathbf{n}_j - \\mathbf{n})k(\\mathbf{n}_j, \\mathbf{n}) = -\\frac{1}{h} \\sum_{j=1}^{M}\\omega_j \\gamma 2(\\mathbf{n} - \\mathbf{n}_j)k(\\mathbf{n}_j, \\mathbf{n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'recreate_paper', 'dataset_sample.pkl'), 'rb') as f:\n",
    "    x_sample, potential_sample, wavefunction_sample, energies_sample, density_sample, kenergies_sample, _, G, h = unpack_dataset(params['N'], pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = density_sample\n",
    "\n",
    "f_deriv = functional_derivative(X_sample, X_train, weights, gamma, h)[0, :]\n",
    "f_deriv_paper = functional_derivative(X_sample, X_train, paper_weights, gamma, h)[0, :]\n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.plot(x, f_deriv, 'r')\n",
    "plt.plot(x, -potential_sample[0], '--k')\n",
    "plt.ylim([-40, 40])\n",
    "plt.grid(True)\n",
    "plt.legend(['MLA', 'Exact'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = params['m']\n",
    "\n",
    "norm_closest = np.sum(np.square(X_sample - X_train), -1)\n",
    "idx = np.argpartition(norm_closest, m)\n",
    "X_closest = X_train[idx[:m]]\n",
    "\n",
    "plt.figure(figsize=(10, 2), dpi=200)\n",
    "#plt.plot(x, X_sample[0], 'r')\n",
    "#plt.plot(x, X_closest[0:1, :].transpose(), 'g', alpha=0.8)\n",
    "plt.plot(x, X_train[idx[m:]].transpose(), 'k', alpha=0.1)#, alpha=0.8)\n",
    "plt.plot(x, X_closest.transpose(), 'g', alpha=0.2)\n",
    "plt.plot(x, X_sample[0], 'r')\n",
    "plt.grid()\n",
    "plt.xlabel('x / bohr')\n",
    "plt.ylabel('probability density')\n",
    "#plt.legend(['sample density', 'nearest m densities', 'all training densities'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = params['l']\n",
    "X = X_sample - X_closest\n",
    "C = np.matmul(np.transpose(X), X)/m\n",
    "\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(C)\n",
    "eigen_vals = np.real(eigen_vals)\n",
    "eigen_vecs = np.real(eigen_vecs)\n",
    "\n",
    "select_eigen_vecs = eigen_vecs[:, :l]\n",
    "P_ml = np.matmul(select_eigen_vecs, np.transpose(select_eigen_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_deriv_proj = np.matmul(P_ml, f_deriv)\n",
    "f_deriv_paper_proj = np.matmul(P_ml, f_deriv_paper)\n",
    "potential_proj = np.matmul(P_ml, -potential_sample[0])\n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.plot(x, np.zeros_like(x), 'k', alpha=0.2)\n",
    "plt.plot(x, f_deriv_proj, 'r', label=\"MLA\")\n",
    "plt.plot(x, potential_proj, '--k', label='Exact (projected functional derivative)')\n",
    "plt.plot(x, -potential_sample[0], '--g', label='Actual functional derivative')\n",
    "plt.ylim([-10, 25])\n",
    "plt.xlabel('x / bohr')\n",
    "plt.ylabel('functional derivative')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_kernel_ridge_regession.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
