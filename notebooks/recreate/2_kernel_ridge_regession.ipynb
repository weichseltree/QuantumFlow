{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/Projects/QuantumFlow/notebooks/recreate\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if tf.test.gpu_device_name() == '/device:GPU:0':\n",
    "    print('Found GPU')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, HTML, display\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from quantumflow.calculus_utils import integrate, integrate_simpson, laplace\n",
    "from quantumflow.numerov_solver import unpack_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../data\"\n",
    "dataset = \"recreate_paper\"\n",
    "test_dataset = \"recreate\"\n",
    "\n",
    "N = 1\n",
    "lambda_coeff = 12.0*10**-14\n",
    "sigma = 43\n",
    "\n",
    "with open(os.path.join(datadir, dataset, 'dataset.pkl'), 'rb') as f:\n",
    "    np_x, np_potentials, np_wavefunctions, np_energies, np_densities, np_kenergies, M, G, h = unpack_dataset(N, pickle.load(f))\n",
    "    \n",
    "with open(os.path.join(datadir, test_dataset, 'dataset.pkl'), 'rb') as f:\n",
    "    _, np_test_potentials, _, _, np_test_densities, np_test_kenergies, M_test, _, _ = unpack_dataset(N, pickle.load(f))\n",
    "\n",
    "\n",
    "X_train = np_densities\n",
    "X_test = np_test_densities\n",
    "\n",
    "y_train = np_kenergies\n",
    "y_test = np_test_kenergies\n",
    "\n",
    "T_mean = np.mean(y_train)\n",
    "\n",
    "print(\"T_mean:\", T_mean)\n",
    "print(\"lambda:\", lambda_coeff)\n",
    "print(\"sigma:\", sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Kernel Ridge Regression\n",
    "###Paper:\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = \\bar{T}\\sum_{j=1}^{M}\\alpha_j k(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$k(\\mathbf{n}, \\mathbf{n}') = \\text{exp}(-\\| \\mathbf{n} - \\mathbf{n}'\\|^2/(2\\sigma^2))$$\n",
    "\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\alpha}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\lambda \\|\\alpha\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "### Sklearn:\n",
    "\n",
    "$$T^{\\text{ML}}(\\mathbf{n}) = 1\\sum_{j=1}^{M}\\omega_j \\tilde{k}(\\mathbf{n}_j, \\mathbf{n})$$\n",
    "\n",
    "$$\\tilde{k}(\\mathbf{n}, \\mathbf{n}') =  \\text{exp}(-\\gamma~\\| \\mathbf{n} - \\mathbf{n}'\\|^2)$$\n",
    "\n",
    "$$\\text{Optimize}:~~~~\\mathcal{C}(\\mathbf{\\omega}) = \\sum_{j=1}^{M}\\ (T_j^{\\text{ML}} - T_j)^2 + \\tilde{\\alpha} \\|\\omega\\|^2$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\\omega = \\bar{T} \\alpha$$\n",
    "$$\\gamma = \\frac{1}{2\\sigma^2}$$\n",
    "$$\\tilde{\\alpha} = \\frac{1}{\\bar{T}^2} \\lambda$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "alpha = lambda_coeff/(T_mean**2)\n",
    "gamma = 1/(2*sigma**2)\n",
    "\n",
    "clf = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "absolute_error = np.abs(y_predict - y_test)\n",
    "MAE = np.mean(absolute_error)\n",
    "ae_std = np.std(absolute_error)\n",
    "ae_max = np.max(absolute_error)\n",
    "\n",
    "\n",
    "kcalmol_per_hartree = 627.51\n",
    "\n",
    "print(\"MAE:\", MAE*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"std:\", ae_std*kcalmol_per_hartree, \"kcal/mol\")\n",
    "print(\"max:\", ae_max*kcalmol_per_hartree, \"kcal/mol\")\n",
    "\n",
    "print(\"\\nrelative error:\", np.mean(absolute_error/y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = clf.dual_coef_\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(weights)\n",
    "plt.title(\"Distribution of weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functional derivative\n",
    "\n",
    "$$ \\frac{1}{\\Delta x} \\nabla T^\\text{ML}(\\mathbf{n}) = \\bar{T}\\sum_{j=1}^{M}\\alpha_j'(\\mathbf{n}_j - \\mathbf{n})k(\\mathbf{n}_j, \\mathbf{n}) = \\frac{1}{h} \\sum_{j=1}^{M}\\omega_j \\gamma 2(\\mathbf{n}_j - \\mathbf{n})k(\\mathbf{n}_j, \\mathbf{n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X, X_train, gamma):\n",
    "    return np.exp(-gamma*np.sum(np.square(X[:, :, np.newaxis] - np.transpose(X_train)[np.newaxis, :, :]), 1))\n",
    "\n",
    "def predict(X, X_train, weights, gamma):\n",
    "    return np.sum(weights[np.newaxis, :]*rbf_kernel(X, X_train, gamma), 1)\n",
    "\n",
    "def functional_derivative(X, X_train, weights, gamma):\n",
    "    return 1/h*np.sum(weights[np.newaxis, :]*2*gamma*(X[:, :, np.newaxis] - np.transpose(X_train)[np.newaxis, :, :])*rbf_kernel(X, X_train, gamma)[:, np.newaxis, :], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = \"recreate_sample\"\n",
    "\n",
    "with open(os.path.join(datadir, sample_dataset, 'dataset.pkl'), 'rb') as f:\n",
    "    np_x_sample, np_potential_sample, np_wavefunction_sample, np_energies_sample, np_density_sample, np_kenergies_sample, _, G, h = unpack_dataset(N, pickle.load(f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_density_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = np_density_sample\n",
    "\n",
    "f_deriv = functional_derivative(X_sample, X_train, weights, gamma)[0, :]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np_x, f_deriv, 'r')\n",
    "plt.plot(np_x, np_potential_sample[0], '--k')\n",
    "plt.ylim([-40, 40])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 30\n",
    "\n",
    "norm_closest = np.sum(np.square(X_sample - X_train), -1)\n",
    "idx = np.argpartition(norm_closest, m)\n",
    "X_closest = X_train[idx[:m]]\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(np_x, X_train[idx[m:]].transpose(), 'k', alpha=0.1)\n",
    "plt.plot(np_x, X_closest.transpose(), 'g', alpha=0.2)\n",
    "plt.plot(np_x, X_sample[0], 'C0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 5\n",
    "X = X_sample - X_closest\n",
    "C = np.matmul(np.transpose(X), X)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(C)\n",
    "eigen_vals = np.real(eigen_vals)\n",
    "eigen_vecs = np.real(eigen_vecs)\n",
    "\n",
    "eigen_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_eigen_vecs = eigen_vecs[:, :l]\n",
    "P_ml = np.matmul(select_eigen_vecs, np.transpose(select_eigen_vecs))\n",
    "P_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_deriv_proj = np.matmul(P_ml, f_deriv)\n",
    "potential_proj = np.matmul(P_ml, np_potential_sample[0])\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "plt.plot(np_x, np.zeros_like(np_x), 'k', alpha=0.2)\n",
    "plt.plot(np_x, f_deriv_proj, 'r', label=\"MLA\")\n",
    "plt.plot(np_x, potential_proj, '--k', label='Exact (projected functional derivative)')\n",
    "plt.plot(np_x, potential_sample, '--g', label='Actual functional derivative')\n",
    "plt.ylim([-25, 10])\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2_kernel_ridge_regession.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
