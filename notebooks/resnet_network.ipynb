{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.DEBUG)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install -q ruamel.yaml\n",
    "    !pip install -q tensorboard-plugin-profile\n",
    "    project_path = '/content/drive/MyDrive/Colab Projects/quantumflow'\n",
    "except:\n",
    "    project_path = os.path.expanduser('~/quantumflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_path)\n",
    "sys.path.append(project_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "\n",
    "import quantumflow\n",
    "\n",
    "experiment = 'resnets'\n",
    "run_name = 'resnet_100'\n",
    "\n",
    "base_dir = os.path.join(project_path, \"experiments\", experiment)\n",
    "params = quantumflow.utils.load_yaml(os.path.join(base_dir, f'{experiment}.yaml'))[run_name]\n",
    "run_dir = os.path.join(base_dir, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %tensorboard --logdir=\"$base_dir\" --load_fast=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset dataset.hdf5 saved to /home/manuel/quantumflow/experiments/snyder_2012/recreate_dataset\n",
      "dataset dataset.hdf5 saved to /home/manuel/quantumflow/experiments/snyder_2012/validate_dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_train = quantumflow.instantiate(params['dataset_train'], run_dir=run_dir)\n",
    "dataset_train.build()\n",
    "\n",
    "dataset_validate = quantumflow.instantiate(params['dataset_validate'], run_dir=run_dir)\n",
    "dataset_validate.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "density (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 500, 1)       0           density[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 500, 32)      3232        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 32)      102432      conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 500, 32)      0           conv1d_1[0][0]                   \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 500, 32)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      102432      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 32)      102432      conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 500, 32)      0           conv1d_3[0][0]                   \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 500, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 500, 32)      102432      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 500, 32)      102432      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 500, 32)      0           conv1d_5[0][0]                   \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 500, 32)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 500, 1)       3201        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kinetic_energy_density (Lambda) (None, 500)          0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kinetic_energy (IntegrateLayer) (None,)              0           kinetic_energy_density[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 518,593\n",
      "Trainable params: 518,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.profiler.experimental.server.start(6009)\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(params['seed'])\n",
    "\n",
    "model = quantumflow.instantiate(params['model'], run_dir=run_dir, dataset=dataset_train)\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "for var in model.variables:\n",
    "    print(f\"{np.prod(var.shape):>4d}\", var.name, var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236/2238174963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tree'"
     ]
    }
   ],
   "source": [
    "from quantumflow.utils import anim_plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = tree.map_structure(lambda feature: feature[10:11], dataset_validate.features)\n",
    "sample_targets = tree.map_structure(lambda target: target[10:11], dataset_validate.targets)\n",
    "sample_targets_pred = model(sample_features)\n",
    "sample = tree.map_structure(lambda target, target_pred: (target[0], target_pred.numpy()[0]), sample_targets, sample_targets_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_path, (target, target_pred) in tree.flatten_with_path_up_to(sample_targets, sample):\n",
    "    target_name = '/'.join(target_path)\n",
    "    \n",
    "    if np.squeeze(target).shape == dataset_validate.x.shape:\n",
    "\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(dataset_validate.x, target, 'k:')\n",
    "        plt.plot(dataset_validate.x, np.squeeze(target_pred))\n",
    "        plt.title(target_name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{target_name}: {target_pred} ({target})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = None\n",
    "tensors = {}\n",
    "\n",
    "def plot_layer(layer):\n",
    "    global value, tensors\n",
    "    \n",
    "    if isinstance(layer, tf.keras.Model):\n",
    "        tree.traverse(plot_layer, layer.layers)\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        value = sample_features[layer.name]\n",
    "        tensors[layer.output.name] = value\n",
    "        \n",
    "    elif isinstance(layer, tf.keras.layers.Layer):\n",
    "        if isinstance(layer.input, list):\n",
    "            value = layer([tensors[inp.name] for inp in layer.input])\n",
    "        else:\n",
    "            value = layer(tensors[layer.input.name])\n",
    "        tensors[layer.output.name] = value\n",
    "\n",
    "_ = tree.traverse(plot_layer, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, tensor in tensors.items():\n",
    "    if len(tensor.shape) == 3:\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(tensor[0])\n",
    "        plt.title(layer_name)\n",
    "        plt.show()\n",
    "    elif np.prod(tensor.shape) < 100:\n",
    "        print(layer_name, tensor)\n",
    "    else:\n",
    "        print(layer_name, tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise YouShallNotPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /home/manuel/quantumflow/experiments/resnets/resnet_100/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "optimizer = quantumflow.instantiate(params['optimizer'])\n",
    "\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    loss=params['loss'], \n",
    "    loss_weights=params.get('loss_weights', None), \n",
    "    metrics=params.get('metrics', None)\n",
    ")\n",
    "\n",
    "\n",
    "if params.get('load_checkpoint', None) is not None:\n",
    "    model.load_weights(os.path.join(data_dir, params['load_checkpoint']))\n",
    "    if params['fit'].get('verbose', 0) > 0:\n",
    "        print(\"loading weights from \", os.path.join(data_dir, params['load_checkpoint']))\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "\n",
    "if run_dir is not None and params.get('checkpoint', False):\n",
    "    checkpoint_params = params['checkpoint'].copy()\n",
    "    checkpoint_params['filepath'] = os.path.join(run_dir, checkpoint_params.pop('filename', 'weights.{epoch:05d}.hdf5'))\n",
    "    checkpoint_params['verbose'] = checkpoint_params.get('verbose', min(1, params['fit'].get('verbose', 1)))\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(**checkpoint_params))\n",
    "\n",
    "\n",
    "if 'tensorboard' in params:\n",
    "    callbacks.append(\n",
    "        quantumflow.instantiate(params['tensorboard'], log_dir=run_dir, learning_rate=optimizer.learning_rate))\n",
    "\n",
    "\n",
    "model.fit(x=dataset_train.features, \n",
    "          y=dataset_train.targets, \n",
    "          callbacks=callbacks,\n",
    "          validation_data=(dataset_validate.features, dataset_validate.targets) if dataset_validate is not None else None,\n",
    "          **params['fit'])\n",
    "\n",
    "if params['save'] is True:\n",
    "    save_model = getattr(model, params['save_model']) if not params.get('save_model', 'self') == 'self' else model\n",
    "    save_model.save(os.path.join(run_dir, 'saved_model'), include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOnjoWzd/gc4HbCp8FvSubN",
   "collapsed_sections": [],
   "name": "train_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
