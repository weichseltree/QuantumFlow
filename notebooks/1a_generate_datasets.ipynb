{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"Projects/QuantumFlow/notebooks\"\n",
    "try:\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/\" + notebook_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "This code is not compatible with eager execution.\n",
    "Please use Tensorflow 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-gpu==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate M random potentials on [0, L] as sum of n gaussian kernels on G discretization points\n",
    "\n",
    "\n",
    "there are 3 uniformly distributed random parameters a, b, c\n",
    "the potential is calculated by:\n",
    "\n",
    "$$\n",
    "V(x) = -\\sum_{n=1}^{3} a_n \\exp \\left(-\\frac{(x - b_n)^2}{2c_n^2} \\right)\n",
    "$$\n",
    "\n",
    "### Then solve the schroedinger equation in atomic units for 4 spinless non-interacting fermions.\n",
    "\n",
    "The shooting numerov algorithm calculates a forward pass and a backward pass solution.\n",
    "\n",
    "The final solution is then found by aligning the two passes and finding a good split point to concatenate them.\n",
    "\n",
    "All integrals are approximated by the trapezoidal method.\n",
    "The numerical differentiation for the laplacian uses the standard approximation.\n",
    "\n",
    "### Usage:\n",
    "\n",
    "Setting the dataset variable to different values will allow generating all the variations of the datasets:\n",
    "standard, recreate, recreate/fine_0.125, ..., recreate/fine_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from quantumflow.generate_potentials import generate_potentials\n",
    "from quantumflow.calculus_utils import integrate, integrate_simpson, laplace\n",
    "from quantumflow.numerov_solver import *\n",
    "from quantumflow.colab_train_utils import test_colab_devices, unpack_dataset\n",
    "test_colab_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_parameters(dataset_name):  \n",
    "    seed = 0\n",
    "    \n",
    "    if \"recreate\" in dataset_name:\n",
    "        N = 4 # number of electrons\n",
    "        \n",
    "        M = dataset_size = 2000 # train dataset size\n",
    "        M_val = M # validation dataset size\n",
    "        M_test = M # test dataset size\n",
    "        \n",
    "        G = points = 500 # discretization points\n",
    "        length = 1.0 # [Bohr]\n",
    "\n",
    "        n_gauss = 3\n",
    "        a_minmax = (1.0, 10.0) # [hartree] \n",
    "        b_minmax = (0.4, 0.6) # nomalized x\n",
    "        c_minmax = (0.03, 0.1) # normalized x\n",
    "\n",
    "        # recreate/fine_n\n",
    "        if \"fine\" in dataset:\n",
    "            factor = float(dataset.split('_')[-1])\n",
    "            G = points = int((500-1)*factor+1)\n",
    "            M_val = None\n",
    "            M_test = None\n",
    "        \n",
    "        if \"seed\" in dataset:\n",
    "            seed = int(dataset.split('_')[-1])\n",
    "            M = 100\n",
    "            M_val = None\n",
    "            M_test = None\n",
    "\n",
    "    elif \"standard\" in dataset_name:\n",
    "        N = 4 # number of electrons\n",
    "        \n",
    "        M = dataset_size = 5000 # train dataset size\n",
    "        M_val = M # validation dataset size\n",
    "        M_test = M # test dataset size\n",
    "        \n",
    "        G = points = 1001 # discretization points\n",
    "        length = 20.0 # [Bohr]\n",
    "\n",
    "        n_gauss = 5\n",
    "        a_minmax = (0.0/n_gauss, 50.0/n_gauss) # [hartree] \n",
    "        b_minmax = (.3, 0.7) # nomalized x\n",
    "        c_minmax = (.02, 0.06) # normalized x\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"dataset parameters for name '{}' not defined.\".format(dataset_name))\n",
    "        \n",
    "    return M, M_val, M_test, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core part of this file:\n",
    "change the datasets variable for creating different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "datasets = []\n",
    "\n",
    "datasets += [\"recreate\", \"standard\"]\n",
    "datasets += [\"recreate/seed_\" + str(seed) for seed in range(1, 10)]\n",
    "datasets += [\"recreate/fine_\" + str(factor) for factor in [0.125, 0.25, 0.5, 1, 2, 5, 8, 10]]\n",
    "\n",
    "progress = widgets.IntProgress(value=0, max=0, description='init...', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        M, M_val, M_test, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax = dataset_parameters(dataset)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    directory = os.path.join(datadir, dataset)\n",
    "    if not os.path.exists(os.path.join(datadir, dataset)):\n",
    "            os.makedirs(os.path.join(datadir, dataset))\n",
    "\n",
    "    for dataset_size, extension in zip([M, M_val, M_test], [\"_training\", \"_validation\", \"_testing\"]):\n",
    "        if dataset_size is None:\n",
    "            continue\n",
    "\n",
    "        np_potentials, np_x = generate_potentials(dataset_size=dataset_size, points=G, n_gauss=n_gauss, length=length,\n",
    "                                                  a_minmax=a_minmax, b_minmax=b_minmax, c_minmax=c_minmax, \n",
    "                                                  return_x=True, seed=seed)\n",
    "\n",
    "        h = (max(np_x) - min(np_x))/(G-1)\n",
    "\n",
    "        np_E, np_solutions = NumerovSolver(G, h).solve_schroedinger(np_potentials, N, progress=progress)\n",
    "        \n",
    "        filename = 'dataset' + extension + '.pkl'\n",
    "        with open(os.path.join(directory, filename), 'wb') as f:\n",
    "            pickle.dump({'x': np_x, 'potential': np_potentials, 'wavefunctions': np_solutions, 'energies': np_E}, f)\n",
    "\n",
    "        print(\"dataset\", filename, \"saved to\", directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "dataset = \"recreate\"\n",
    "\n",
    "N = 1\n",
    "    \n",
    "with open(os.path.join(datadir, dataset, 'dataset_training.pkl'), 'rb') as f:\n",
    "    np_x, np_potentials, np_wavefunctions, np_energies, np_densities, np_kenergies, M, G, h = unpack_dataset(N, pickle.load(f))\n",
    "    \n",
    "with open(os.path.join(datadir, 'recreate_paper', 'dataset_sample.pkl'), 'rb') as f:\n",
    "    _, _, _, _, np_sample_density, _, _, _, _ = unpack_dataset(N, pickle.load(f))\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.fill_between(np_x, np.min(np_wavefunctions[:, :, 0]**2, axis=0), \n",
    "                       np.max(np_wavefunctions[:, :, 0]**2, axis=0), facecolor='0.9')\n",
    "\n",
    "plt.plot(np_x, np.transpose(np_sample_density[0]), 'r')\n",
    "#plt.plot(np_x, np.transpose(np_sample_density[0]), '--k')\n",
    "\n",
    "plt.title('Density Variation for N='+str(N))\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 3.2])\n",
    "plt.xlabel('x / bohr')\n",
    "plt.ylabel('probability density $n(x)$')\n",
    "#plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"recreate\"\n",
    "M, _, _, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax = dataset_parameters(dataset)\n",
    "\n",
    "print(\"Dataset:\", dataset)\n",
    "print(\"\")\n",
    "print(\"dataset size M:\", M)\n",
    "print(\"discretiation points G:\", G)\n",
    "print(\"1D box length:\", length, 'bohr')\n",
    "print(\"\")\n",
    "print(\"potential function parameters:\")\n",
    "print(\"seed:\", seed)\n",
    "print(\"number of gaussian functions:\", n_gauss)\n",
    "print(\"a uniform: \", list(a_minmax))\n",
    "print(\"b uniform: \", list(b_minmax))\n",
    "print(\"c uniform: \", list(c_minmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_potentials, np_x = generate_potentials(dataset_size=M, points=G, n_gauss=n_gauss, length=length,\n",
    "                                          a_minmax=a_minmax, b_minmax=b_minmax, c_minmax=c_minmax, \n",
    "                                          return_x=True, seed=seed)\n",
    "h = (max(np_x) - min(np_x))/(G-1) # discretization width [bohr]\n",
    "\n",
    "preview = 5\n",
    "\n",
    "#plt.figure(figsize=(10, 2), dpi=200)\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np_x, np.transpose(np_potentials)[:, :preview]) # only plot first potentials\n",
    "plt.title(\"Randomly Generated Potentials\")\n",
    "plt.xlabel(\"x / bohr\")\n",
    "plt.ylabel(\"Energy / hartree\")\n",
    "plt.grid(which='major', axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "solver = NumerovSolver(G, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "split_energies, steps = solver.find_split_energies(np_potentials, N, progress=progress)\n",
    "print(\"found all split energies in\", steps, \"steps\")\n",
    "print(\"shape:\", split_energies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "bins = np.linspace(min(split_energies.flatten()), max(split_energies.flatten()), 100)\n",
    "\n",
    "for i in range(split_energies.shape[1]):\n",
    "    color = i/(split_energies.shape[1] - 1)\n",
    "    plt.hist(split_energies[:, i], bins, alpha=0.7, color=[0.8*color**2, 0.8*(1-color)**2, 1.6*color*(1-color)], label= str(i) + \" roots\")\n",
    "\n",
    "plt.xlabel('split energy / hartree')\n",
    "plt.ylabel('count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Energies giving the intervals where there is exactly one eigenvalue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "target_roots = np.repeat(np.expand_dims(np.arange(N), axis=0), M, axis=0)\n",
    "np_solutions_forward, np_E_forward, steps = solver.solve_numerov(np_potentials, target_roots, split_energies, progress=progress)\n",
    "np_solutions_forward /= np.expand_dims(np.nanmax(np.abs(np_solutions_forward), axis=1), axis=1)\n",
    "print(\"steps to convergence: \", steps)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions_forward), axis=1))\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Numerov Forward Pass Solutions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "np_solutions_backward, np_E_backward, steps = solver.solve_numerov(np.flip(np_potentials, axis=1), target_roots, split_energies, progress=progress)\n",
    "np_solutions_backward = np.flip(np_solutions_backward, axis=1)\n",
    "np_solutions_backward /= np.expand_dims(np.nanmax(np.abs(np_solutions_backward), axis=1), axis=1)\n",
    "print(\"steps to convergence: \", steps)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions_backward), axis=1))\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_backward[:preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "    plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Numerov Backward Pass Solutions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_factor = np_solutions_forward/np_solutions_backward\n",
    "np_median = np.nanmedian(np_factor, axis=1)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_factor), axis=1))\n",
    "\n",
    "merge_preview = 1\n",
    "merge_preview_n_max = 4\n",
    "\n",
    "fig, axs = plt.subplots(N, 1, figsize=(20, 8))\n",
    "for i, np_plot in enumerate(np_factor[:merge_preview]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        axs[n].plot(np_x, np.ones(np_x.shape)*np_median[i, n], 'r', label=\"median\")\n",
    "        axs[n].plot(np_x, np_plot_single, 'C' + str(i%10), label=\"forward/backward\")\n",
    "        if n == 0: axs[n].legend(loc='best')\n",
    "fig.suptitle('Factor between forward an backward pass, should be 1.0, some spikes near zeroes of the wavefunction, median as red line')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_solutions_backward_scaled = np_solutions_backward*np.expand_dims(np_median, axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_backward_scaled[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.title('Scaled backwards pass with forward pass. Now they have equal signs and should match nicely for the most part')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:merge_preview] - np_solutions_backward_scaled[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Difference in forward and backward pass')\n",
    "plt.show()\n",
    "\n",
    "join_error = np.nanmax(np.abs(np_solutions_backward_scaled - np_solutions_forward), axis=1)\n",
    "print(\"maximal absolute errors:\")\n",
    "print(join_error[:merge_preview])\n",
    "print(\"dataset maximal absolute error:\", np.max(join_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_index = np.nanargmin(np.abs(np_solutions_backward_scaled - np_solutions_forward), axis=1)\n",
    "join_mask = np.expand_dims(np.expand_dims(np.arange(np_solutions_backward_scaled.shape[1]), axis=0), axis=2) >= np.expand_dims(join_index, axis=1)\n",
    "\n",
    "np_solutions = np_solutions_forward.copy()\n",
    "np_solutions[join_mask] = np_solutions_backward_scaled[join_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions[:merge_preview]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        plt.plot(np_x[:join_index[i, n]], np_solutions_forward[i, :join_index[i, n], n], 'g')\n",
    "        plt.plot(np_x[join_index[i, n]-1:], np_solutions_backward_scaled[i, join_index[i, n]-1:, n], 'b')\n",
    "plt.legend(['forward', 'backward'])\n",
    "plt.title('Merged wavefunctions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "np_norm = np_solutions**2\n",
    "np_norm = integrate_simpson(np_norm, h, axis=1)\n",
    "np_solutions *= 1/np.sqrt(np.expand_dims(np_norm, axis=1))\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions), axis=1))\n",
    "\n",
    "print('max energy error:', np.max(np_E_forward - np_E_backward))\n",
    "np_E = 0.5*(np_E_forward + np_E_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, preview, figsize=(10, 4), dpi=200)\n",
    "#fig, axs = plt.subplots(1, preview, figsize=(20, 8))\n",
    "for i, np_plot in enumerate(np_solutions[:preview]**2 + np_E[:preview, np.newaxis, :]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        axs[i].plot(np_x, np_potentials[i], 'k')\n",
    "        axs[i].plot(np_x, np.ones(np_x.shape)*np_E[i, n], ':k')\n",
    "        axs[i].plot(np_x, np_plot_single, 'C' + str(i%10))\n",
    "        axs[i].set_ylim([np.min(np_potentials[:preview]), max(np.max(np_E[:preview]*1.1), 0.5)])\n",
    "        if i == 0: \n",
    "            axs[i].set_ylabel('energies, potential / hartree')\n",
    "            axs[i].set_xlabel(\"x / bohr\")\n",
    "        else:\n",
    "            axs[i].get_yaxis().set_visible(False)\n",
    "#fig.suptitle('Numerov Solution Energies and Densities')\n",
    "plt.show()\n",
    "print('\\neigenvalue energies:\\n', np_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_density = np.sum(np_solutions**2, axis=-1)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np_x, np.transpose(np_potentials)[:, :preview])\n",
    "plt.title('Potential V')\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(20, 4))\n",
    "plt.figure(figsize=(10, 2), dpi=200)\n",
    "for i, np_density_group in enumerate(np_density[:preview]):\n",
    "    plt.plot(np_x, np_density_group, 'C' + str(i%10))\n",
    "#plt.title('Total Density N=' + str(N))\n",
    "plt.xlabel(\"x / bohr\")\n",
    "plt.ylabel(\"probability density\")\n",
    "plt.grid(which='major', axis='y', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(20, 4))\n",
    "plt.figure(figsize=(10, 2), dpi=200)\n",
    "for i, np_density_group in enumerate((np_solutions[:, :, 0]**2)[:preview]):\n",
    "    plt.plot(np_x, np_density_group, 'C' + str(i%10))\n",
    "#plt.title('Density N=1')\n",
    "plt.xlabel(\"x / bohr\")\n",
    "plt.ylabel(\"probability density\")\n",
    "plt.grid(which='major', axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_laplace = laplace(np_solutions, h)\n",
    "np_kinetic = -0.5*np_solutions*np_laplace\n",
    "np_K = integrate_simpson(np_kinetic, h, axis=1)\n",
    "np_potential = np.expand_dims(np_potentials, axis=2)*np_solutions**2\n",
    "np_P = integrate_simpson(np_potential, h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "#plt.figure(figsize=(10, 3), dpi=200)\n",
    "for i, np_solutions_group in enumerate(np_solutions[:preview]):\n",
    "    plt.plot(np_x, np_solutions_group, 'C' + str(i%10), linewidth=1)\n",
    "plt.title('Wavefunctions')\n",
    "plt.xlabel(\"x / bohr\")\n",
    "plt.ylabel(\"normalized wavefunctions\")\n",
    "plt.grid(which='major', axis='y', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_laplace_group in enumerate(np_laplace[:preview]):\n",
    "    plt.plot(np_x, np_laplace_group, 'C' + str(i%10))\n",
    "plt.title('Laplace(Wavefunction)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_kinetic_group in enumerate(np_kinetic[:preview]):\n",
    "    plt.plot(np_x, np_kinetic_group, 'C' + str(i%10))\n",
    "plt.title('Kinetic Energy Density')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_potential_group in enumerate(np_potential[:preview]):\n",
    "    plt.plot(np_x, np_potential_group, 'C' + str(i%10))\n",
    "plt.title('Potential Energy Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy = np.sum(np_E, axis=-1)\n",
    "print('total energy:', total_energy[:5])\n",
    "\n",
    "potential_energy = np.sum(np_P, axis=-1)\n",
    "print('potential energy:', potential_energy[:5])\n",
    "\n",
    "kinetic_energy = np.sum(np_K, axis=-1)\n",
    "print('kinetic energy direct:', kinetic_energy[:5])\n",
    "\n",
    "np_K_id = np_E - np_P\n",
    "kinetic_energy_id = np.sum(np_K_id, axis=-1)\n",
    "print('kinetic energy indirect:', kinetic_energy_id[:5])\n",
    "\n",
    "assert(not np.any(np.isnan(np_density)))\n",
    "assert(not np.any(np.isnan(np_kinetic)))\n",
    "assert(not np.any(np.isnan(kinetic_energy)))\n",
    "assert(not np.any(np.isnan(kinetic_energy_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1a_generate_datasets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
