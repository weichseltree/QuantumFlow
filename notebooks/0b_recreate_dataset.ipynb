{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/Projects/QuantumFlow/notebooks\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if tf.test.gpu_device_name() == '/device:GPU:0':\n",
    "    print('Found GPU')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from quantumflow.generate_potentials import generate_potentials\n",
    "from quantumflow.calculus_utils import integrate, integrate_simpson, laplace\n",
    "from quantumflow.numerov_solver import NumerovSolver\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "paper_coeff = pd.read_csv('../data/paper_potentials.txt', delimiter=' ')\n",
    "paper_coeff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "dataset = \"recreate_paper\"\n",
    "\n",
    "G = 500\n",
    "length = 1\n",
    "N = 4\n",
    "\n",
    "a = paper_coeff[['a1', 'a2', 'a3']].values[:, np.newaxis, :]\n",
    "c = paper_coeff[['b1', 'b2', 'b3']].values[:, np.newaxis, :] # b<->c listed wrong in the paper\n",
    "b = paper_coeff[['c1', 'c2', 'c3']].values[:, np.newaxis, :]\n",
    "\n",
    "np_x = np.linspace(0.0, length, G)\n",
    "curves = -np.square(np_x[np.newaxis, :, np.newaxis] - b)/(2*np.square(c))\n",
    "curves = -a*np.exp(curves)\n",
    "\n",
    "np_potentials = np.sum(curves, -1)\n",
    "\n",
    "h = (max(np_x) - min(np_x))/(G-1) # discretization width [bohr]\n",
    "\n",
    "preview = 5\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np_x, np.transpose(np_potentials)[:, :preview]) # only plot first potentials\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=0, description='init...', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "solver = NumerovSolver(G, h)\n",
    "\n",
    "np_E, np_solutions = solver.solve_schroedinger(np_potentials, N, progress=progress)\n",
    "\n",
    "if not os.path.exists(os.path.join(datadir, dataset)):\n",
    "        os.makedirs(os.path.join(datadir, dataset))\n",
    "\n",
    "with open(os.path.join(datadir, dataset, 'dataset_training.pkl'), 'wb') as f:\n",
    "    pickle.dump([np_x, np_potentials, np_solutions, np_E], f)\n",
    "    \n",
    "print(\"dataset\", dataset, \"saved to\", os.path.join(datadir, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, preview, figsize=(20, 8))\n",
    "for i, np_plot in enumerate(np_solutions[:preview]**2 + np_E[:preview, np.newaxis, :]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        axs[i].plot(np_x, np_potentials[i], 'k')\n",
    "        axs[i].plot(np_x, np.ones(np_x.shape)*np_E[i, n], ':k')\n",
    "        axs[i].plot(np_x, np_plot_single, 'C' + str(i%10))\n",
    "        axs[i].set_ylim([np.min(np_potentials[:preview]), max(np.max(np_E[:preview]*1.1), 0.5)])\n",
    "        if i == 0: axs[i].set_ylabel('energies, potential / hartree')\n",
    "fig.suptitle('Numerov Solution Energies and Densities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreate sample potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters are found by gradient descent further down in the code\n",
    "a = [4.02480191, 5.99455501, 10.76801402]\n",
    "b = [0.52157438, 0.58645736, 0.57318963]\n",
    "c = [0.07131018, 0.03986175, 0.05540802]\n",
    "\n",
    "a = np.array(a)[np.newaxis, np.newaxis, :]\n",
    "b = np.array(b)[np.newaxis, np.newaxis, :]\n",
    "c = np.array(c)[np.newaxis, np.newaxis, :]\n",
    "\n",
    "curves = -np.square(np_x[np.newaxis, :, np.newaxis] - b)/(2*np.square(c))\n",
    "curves = -a*np.exp(curves)\n",
    "\n",
    "np_sample = np.sum(curves, -1)\n",
    "\n",
    "solver = NumerovSolver(G, h)\n",
    "\n",
    "np_E_sample, np_solutions_sample = solver.solve_schroedinger(np_sample, N)\n",
    "\n",
    "if not os.path.exists(os.path.join(datadir, dataset)):\n",
    "        os.makedirs(os.path.join(datadir, dataset))\n",
    "\n",
    "with open(os.path.join(datadir, dataset, 'dataset_sample.pkl'), 'wb') as f:\n",
    "    pickle.dump([np_x, np_sample, np_solutions_sample, np_E_sample], f)\n",
    "    \n",
    "print(\"dataset dataset_sample.pkl saved to\", os.path.join(datadir, dataset))\n",
    "\n",
    "img = plt.imread(\"../data/sample_potential.png\")\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "ax.imshow(img, extent=[0, 1, -40, 40])\n",
    "plt.axis('auto')\n",
    "plt.plot(np_x, np.transpose(np_sample))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = (img[:, :, 0] == 0)*1.0\n",
    "\n",
    "kernel_size = 5\n",
    "kernel = np.ones((kernel_size, kernel_size))/(kernel_size**2)\n",
    "from scipy import ndimage\n",
    "filtered_img = ndimage.convolve(filtered_img, kernel, mode='constant', cval=0.0)\n",
    "filtered_img = (filtered_img > 0.92)*1.0\n",
    "filtered_img[500:, 500:] = 0 # remove legend\n",
    "\n",
    "y_mass = np.sum(filtered_img, axis=0)\n",
    "y_data = np.sum(filtered_img*np.arange(filtered_img.shape[0])[:, np.newaxis], axis=0)/y_mass\n",
    "y_data = -80*(y_data + 1/2 - filtered_img.shape[0]/2)/filtered_img.shape[0]\n",
    "x_data = np.linspace(0, 1, filtered_img.shape[1])+0.5/filtered_img.shape[1]\n",
    "\n",
    "filtered_img = 1 - filtered_img[:, :, np.newaxis]*np.ones((1, 1, 3))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "ax.imshow(filtered_img, extent=[0, 1, -40, 40])\n",
    "plt.axis('auto')\n",
    "plt.plot(x_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data -= np.nanmean(y_data[:100])\n",
    "assert ~np.any(y_data > 0)\n",
    "\n",
    "x_data = x_data[~np.isnan(y_data)]\n",
    "y_data = y_data[~np.isnan(y_data)]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(x_data, y_data, '.k', markersize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solve the nonlinear optimization problem with tensorflow and gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_optimize = 10\n",
    "seed = 0\n",
    "\n",
    "a_minmax=(1.0, 10.0) # [hartree] \n",
    "b_minmax=(0.4, 0.6) # nomalized x\n",
    "c_minmax=(0.03, 0.1) # normalized x\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.random.set_random_seed(seed)\n",
    "\n",
    "a = tf.Variable(tf.random.uniform((n_optimize, 3), minval=a_minmax[0], maxval=a_minmax[1], dtype=tf.float64), name=\"a\")\n",
    "b = tf.Variable(tf.random.uniform((n_optimize, 3), minval=b_minmax[0], maxval=b_minmax[1], dtype=tf.float64), name=\"b\")\n",
    "logc = tf.Variable(tf.random.uniform((n_optimize, 3), minval=np.log(c_minmax[0]), maxval=np.log(c_minmax[1]), dtype=tf.float64), name=\"c\") # avoid negative values\n",
    "\n",
    "fit_x = tf.constant(x_data)\n",
    "fit_y = tf.constant(y_data)\n",
    "fit_weights = tf.constant(x_data)*0 + 1\n",
    "\n",
    "curves = -tf.square(tf.expand_dims(tf.expand_dims(fit_x, 1), 0) - tf.expand_dims(b, 1))/(2*tf.square(tf.expand_dims(tf.exp(logc), 1)))\n",
    "curves = -tf.expand_dims(a, 1)*tf.exp(curves)\n",
    "\n",
    "fit_potentials = tf.reduce_sum(curves, -1)\n",
    "\n",
    "individual_loss = tf.reduce_mean(tf.square(fit_potentials - tf.expand_dims(fit_y, 0)), -1)\n",
    "loss = tf.reduce_sum(individual_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.0002)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "np_a_list = []\n",
    "np_b_list = []\n",
    "np_c_list = []\n",
    "loss_list = []\n",
    "\n",
    "max_iterations = 100000\n",
    "\n",
    "progress = widgets.IntProgress(value=0, max=max_iterations, description='optimizing', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(max_iterations):\n",
    "        np_a, np_b, np_logc = sess.run([a, b, logc])\n",
    "        np_c = np.exp(np_logc)\n",
    "        \n",
    "        np_a_list.append(np_a)\n",
    "        np_b_list.append(np_b)\n",
    "        np_c_list.append(np_c)\n",
    "        \n",
    "        np_loss, _ = sess.run([individual_loss, train])\n",
    "        \n",
    "        loss_list.append(np_loss)\n",
    "    \n",
    "        if step % 1000 == 0:\n",
    "            progress.value = step\n",
    "        \n",
    "    np_a, np_b, np_logc = sess.run([a, b, logc])\n",
    "    np_c = np.exp(np_logc)\n",
    "    \n",
    "    np_a_list.append(np_a)\n",
    "    np_b_list.append(np_b)\n",
    "    np_c_list.append(np_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_a = np.array(np_a_list)\n",
    "np_b = np.array(np_b_list)\n",
    "np_c = np.array(np_c_list)\n",
    "\n",
    "np_x = np.linspace(0.0, length, G)\n",
    "curves = -np.square(np_x[np.newaxis, :, np.newaxis] - np_b[-1, :, np.newaxis])/(2*np.square(np_c[-1, :, np.newaxis]))\n",
    "curves = -np_a[-1, :, np.newaxis]*np.exp(curves)\n",
    "\n",
    "np_potentials = np.sum(curves, -1)\n",
    "\n",
    "print(np_a[0, :, :])\n",
    "print(np_b[0, :, :])\n",
    "print(np_c[0, :, :])\n",
    "print('')\n",
    "print(np_a[-1, :, :])\n",
    "print(np_b[-1, :, :])\n",
    "print(np_c[-1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(x_data, y_data, '.k', markersize=1)\n",
    "plt.plot(np_x, np_potentials.transpose())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_min = np.argmin(loss_list[-1])\n",
    "a_min = np_a_list[-1][index_min]\n",
    "b_min = np_b_list[-1][index_min]\n",
    "c_min = np_c_list[-1][index_min]\n",
    "print(a_min)\n",
    "print(b_min)\n",
    "print(c_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0b_recreate_dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
