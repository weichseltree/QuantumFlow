{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"Projects/QuantumFlow/notebooks\"\n",
    "try:\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/\" + notebook_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "!pip install -q ruamel.yaml\n",
    "!pip install -q tensorflow-addons\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from quantumflow.colab_utils import load_hyperparameters, test_colab_devices, get_resolver, QFDataset\n",
    "\n",
    "has_gpu, has_tpu = test_colab_devices()\n",
    "if has_gpu: print(\"Found GPU\")\n",
    "if has_tpu: print(\"Found TPU\")\n",
    "\n",
    "data_dir = \"../data\"\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "experiment = 'ke_cnn'\n",
    "run_name = 'test'\n",
    "\n",
    "preview = 5\n",
    "figsize = (20, 3)\n",
    "dpi = None\n",
    "kcalmol_per_hartree = 627.51\n",
    "\n",
    "base_dir = os.path.join(data_dir, experiment)\n",
    "log_dir = \"gs://quantumflow/\" + experiment if has_tpu else '/home/' + experiment\n",
    "file_hyperparams = os.path.join(base_dir, \"hyperparams (1).config\")\n",
    "\n",
    "params = load_hyperparameters(file_hyperparams, run_name=run_name)\n",
    "export_dir = os.path.join(base_dir, run_name, 'saved_model')\n",
    "\n",
    "model = tf.saved_model.load(export_dir)\n",
    "\n",
    "dataset_train = QFDataset(os.path.join(data_dir, params['dataset_train'] + '.pkl'), params)\n",
    "dataset_eval = QFDataset(os.path.join(data_dir, params['dataset_validate'] + '.pkl'), params)\n",
    "\n",
    "dataset_test = QFDataset(os.path.join(data_dir,  'recreate/dataset_test.pkl'), params)\n",
    "dataset_sample = QFDataset(os.path.join(data_dir, 'recreate/dataset_sample.pkl'), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_analysis(kinetic_energy, derivative, dataset):\n",
    "    \n",
    "    kenergies_err = np.abs(dataset.kinetic_energy - kinetic_energy)*kcalmol_per_hartree\n",
    "    derivative_err = np.max(np.abs(dataset.derivative - derivative), axis=1)\n",
    "\n",
    "    print('MAE:', np.mean(kenergies_err))\n",
    "    print('AE_std:', np.std(kenergies_err))\n",
    "    print('AE_max:', np.max(kenergies_err))\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.hist(kenergies_err, bins=100)\n",
    "    plt.title('Kinetic Energy Absolute Error')\n",
    "    plt.xlabel('kcal/mol')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.hist(derivative_err, bins=100)\n",
    "    plt.title('Functional Derivative Max Absolute Error')\n",
    "    plt.xlabel('hartree')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model({'density': dataset_test.density})\n",
    "plot_prediction_analysis(predictions['kinetic_energy'], predictions['derivative'], dataset_test)\n",
    "\n",
    "indices = np.argsort(np.abs(predictions['kinetic_energy'] - dataset_test.kinetic_energy), axis=0)\n",
    "largest_error = indices[-1]\n",
    "\n",
    "print('Energy prediction:')\n",
    "print(dataset_test.kinetic_energy[largest_error], predictions['kinetic_energy'].numpy()[largest_error], \" =\", \n",
    "      np.abs(dataset_test.kinetic_energy[largest_error] - predictions['kinetic_energy'][largest_error])*kcalmol_per_hartree, \"kcal/mol\")\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(dataset_sample.x, dataset_train.potential.transpose(), 'k', alpha=0.1)\n",
    "plt.plot(dataset_sample.x, dataset_test.potential[largest_error], 'C0', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(dataset_sample.x, dataset_test.derivative[largest_error], 'C0', linestyle='--')\n",
    "plt.plot(dataset_sample.x, predictions['derivative'][largest_error])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    predictions = model({'density': dataset_sample.density})\n",
    "variables = {variable.name:variable.numpy() for variable in tape.watched_variables()}\n",
    "\n",
    "kinetic_energy_sample = predictions['kinetic_energy']\n",
    "derivative_sample = predictions['derivative']\n",
    "\n",
    "print('Energy prediction:')\n",
    "print(dataset_sample.kinetic_energy[0], kinetic_energy_sample[0], \" =\", np.abs(dataset_sample.kinetic_energy[0]-kinetic_energy_sample[0])*kcalmol_per_hartree, \"kcal/mol\")\n",
    "\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.plot(dataset_sample.x, dataset_sample.derivative[0], 'C0', linestyle='--')\n",
    "plt.plot(dataset_sample.x, derivative_sample[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "for name, value in variables.items():\n",
    "    if 'kernel' not in name or 'conv1d' not in name:\n",
    "        continue\n",
    "    \n",
    "    fig, axs = plt.subplots(value.shape[2], 1, figsize=(figsize[0], 3 + value.shape[2]), dpi=dpi)\n",
    "    if value.shape[2] == 1:\n",
    "        axs = [axs]\n",
    "        \n",
    "    limit = np.max(np.abs(value))*1.1\n",
    "    \n",
    "    for i, kern in enumerate(np.moveaxis(value, 2, 0)):\n",
    "        axs[i].plot(np.arange(len(kern[:, 0]))+1, kern, '.-', markersize=2, linewidth=0.5)\n",
    "        axs[i].plot([1, len(kern)], [0, 0], 'k', linewidth=0.5, zorder=-3)\n",
    "        axs[i].text(6, limit*0.6, 'bias: ' + str(variables[name.replace('kernel', 'bias')][i]))\n",
    "        axs[i].set_ylabel('ch{} out '.format('.' if value.shape[2] > 6 else 'annel') + str(i+1))\n",
    "        axs[i].set_ylim([-limit, limit])\n",
    "        axs[i].set_xlim([1, len(kern)])\n",
    "        \n",
    "        if i == value.shape[2]-1: \n",
    "            axs[i].set_xlabel('index')\n",
    "            axs[i].legend(['channel in ' + str(j+1) for j in range(kern.shape[1])], \n",
    "                          bbox_to_anchor=[1.0, 0.0], loc='lower right')\n",
    "        else:\n",
    "            axs[i].get_xaxis().set_visible(False)\n",
    "        \n",
    "        if i == 0:\n",
    "            axs[i].set_title('layer {}: kernel_size: {}, filters: {}, activation: {}, padding: {}'.format(\n",
    "            l, value.shape[0], value.shape[2], 'softplus' if l != 3 else 'sum', 'valid'), fontsize=10)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([v.name for v in variables])\n",
    "\n",
    "#fig, axs = plt.subplots(value.shape[3], 1, figsize=(6, 2 + value.shape[3]), dpi=200)\n",
    "fig, axs = plt.subplots(len(layers), 1, figsize=(15, len(layers)*2))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "        \n",
    "    length = layer.shape[0]\n",
    "    cutoff = (G - length)//2\n",
    "    cutoffset = (G - length) % 2\n",
    "    \n",
    "    limit = np.max(np.abs(layer))*1.1\n",
    "\n",
    "    axs[i].plot(np.arange(G-cutoff*2-cutoffset)+1, layer)#, '.-', markersize=2, linewidth=0.5)\n",
    "    axs[i].set_ylim(-limit/10, limit)\n",
    "    axs[i].set_xlim([-cutoff+1, G-cutoff])\n",
    "    axs[i].grid(which='major', axis='y', linestyle='--')\n",
    "    axs[i].set_xticks([1, length])\n",
    "    \n",
    "    axs[i].set_ylabel((i != len(layers)-1)*('layer ' + str(i)) + ' output' if i > 0 else 'input')\n",
    "    if len(layer.shape) > 1:\n",
    "        axs[i].legend(['channel ' + str(j+1) if j < 4 else '...' for j in range(layer.shape[1])][:5], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_variables = {id(v) for v in model.variables}\n",
    "print(trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = QFDataset(os.path.join(data_dir, 'recreate/dataset_sample.pkl'), params)\n",
    "\n",
    "predictions_n = {key:[] for key in params['targets']}\n",
    "\n",
    "@tf.function\n",
    "def sample_step(batch):\n",
    "    features, targets = batch\n",
    "\n",
    "    predictions = model(features)\n",
    "    loss, losses = calc_loss(model, targets, predictions)\n",
    "    \n",
    "    return predictions, losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_plot(np.stack([predictions_n['derivative'], np.repeat(dataset_sample.derivative, len(predictions_n['derivative']), axis=0)], axis=2)[::100], dataset_sample.x, interval=10, figsize=(15, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summaries(event_dir):\n",
    "    import pandas as pd\n",
    "\n",
    "    event_files = [os.path.join(event_dir, file) for file in os.listdir(event_dir) if '.tfevents' in file]\n",
    "\n",
    "    values = {'wall_time': ([], [])}\n",
    "\n",
    "    for raw_record in tf.data.TFRecordDataset(event_files):\n",
    "        print(raw_record)\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        print(example)\n",
    "\n",
    "        continue\n",
    "        if summary.summary.value.__len__() == 0: continue      \n",
    "\n",
    "        if summary.step not in values['wall_time'][0]:\n",
    "            values['wall_time'][0].append(summary.step)\n",
    "            values['wall_time'][1].append(summary.wall_time)\n",
    "\n",
    "        for entry in summary.summary.value:\n",
    "            try:\n",
    "                if summary.step not in values[entry.tag][0]:\n",
    "                    values[entry.tag][0].append(summary.step)\n",
    "                    values[entry.tag][1].append(entry.simple_value)\n",
    "\n",
    "            except KeyError:\n",
    "                values[entry.tag] = ([summary.step], [entry.simple_value])\n",
    "                    \n",
    "    for key in values.keys():        \n",
    "        values[key] = pd.DataFrame(values[key][1], index=values[key][0], columns=[key])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_train = load_summaries(os.path.join(data_dir, experiment, run_name))\n",
    "summary_eval = load_summaries(os.path.join(data_dir, experiment, run_name, 'eval'))\n",
    "print(summary_train.keys(), summary_eval.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np.log10(summary_train['loss']))\n",
    "plt.plot(np.log10(summary_train['loss'].ewm(com=10).mean()))\n",
    "plt.plot(np.log10(summary_eval['loss']))\n",
    "plt.show()\n",
    "\n",
    "print(summary_train['global_step/sec'].mean()[0], 'global_step/sec')\n",
    "print(summary_train['examples/sec'].mean()[0], 'examples/sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_train_ens = [load_summaries(os.path.join(data_dir, experiment, run_name)) for run_name in ensemble_run_names]\n",
    "summary_eval_ens = [load_summaries(os.path.join(data_dir, experiment, run_name, 'eval')) for run_name in ensemble_run_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i, summary_e in enumerate(summary_train_ens): \n",
    "    plt.plot(summary_e['loss'].ewm(com=20).mean(), 'C' + str(i))\n",
    "for i, summary_e in enumerate(summary_eval_ens): \n",
    "    plt.plot(summary_e['loss'], '--C' + str(i))\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.ylim([10**(-4.5), 10**-2])\n",
    "plt.xlim([0, 1000000])\n",
    "plt.legend([name.replace('_', ': ') for name in ensemble_run_names] + [name.replace('_', ': ') + ', eval' for name in ensemble_run_names], ncol=2)\n",
    "plt.grid()\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, summary_e in enumerate(summary_eval_ens): \n",
    "    plt.plot(summary_e['value_mae']*kcalmol_per_hartree, '--C' + str(i))\n",
    "\n",
    "#plt.yscale('log')\n",
    "plt.ylim([0, 6])\n",
    "plt.xlim([0, 1000000])\n",
    "plt.legend([name.replace('_', ': ') + ', eval' for name in ensemble_run_names])\n",
    "plt.grid()\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('kinetic energy: mean absolute error / kcal/mol')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, summary_e in enumerate(summary_eval_ens): \n",
    "    plt.plot(summary_e['derivative_mae'], '--C' + str(i))\n",
    "\n",
    "plt.xlim([0, 1000000])\n",
    "plt.legend([name.replace('_', ': ') + ', eval' for name in ensemble_run_names])\n",
    "plt.grid()\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('derivative: mean absolute error / hartree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3b_cnn_analysis_kenergy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
