{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate M random potentials on [0, L] as sum of n gaussian kernels on G discretization points\n",
    "\n",
    "\n",
    "there are 3 uniformly distributed random parameters a, b, c\n",
    "the potential is calculated by:\n",
    "\n",
    "$$\n",
    "V(x) = -\\sum_{n=1}^{3} a_n \\exp \\left(-\\frac{(x - b_n)^2}{2c_n^2} \\right)\n",
    "$$\n",
    "\n",
    "### Then solve the schroedinger equation in atomic units for 4 spinless non-interacting fermions.\n",
    "\n",
    "The shooting numerov algorithm calculates a forward pass and a backward pass solution.\n",
    "\n",
    "The final solution is then found by aligning the two passes and finding a good split point to concatenate them.\n",
    "\n",
    "All integrals are approximated by the trapezoidal method.\n",
    "The numerical differentiation for the laplacian uses the standard approximation.\n",
    "\n",
    "### Usage:\n",
    "\n",
    "Setting the dataset variable to different values will allow generating all the variations of the datasets:\n",
    "standard, recreate, recreate/fine_0.125, ..., recreate/fine_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization and shared files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-gpu==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/Projects/QuantumFlow/notebooks\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if tf.test.gpu_device_name() == '/device:GPU:0':\n",
    "    print('Found GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate_potentials.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../quantumflow/generate_potentials.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def tf_generate_potentials(dataset_size=2000, points=500, n_gauss=3, length=1.0,\n",
    "                           a_minmax=(0.0, 3*10.0), b_minmax=(0.4, 0.6), c_minmax=(0.03, 0.1), return_x=False):\n",
    "    x = tf.linspace(0.0, length, points, name=\"x\")\n",
    "\n",
    "    a = tf.random_uniform((dataset_size, 1, n_gauss), minval=a_minmax[0], maxval=a_minmax[1], name=\"a\")\n",
    "    b = tf.random_uniform((dataset_size, 1, n_gauss), minval=b_minmax[0]*length, maxval=b_minmax[1]*length, name=\"b\")\n",
    "    c = tf.random_uniform((dataset_size, 1, n_gauss), minval=c_minmax[0]*length, maxval=c_minmax[1]*length, name=\"c\")\n",
    "\n",
    "    curves = -tf.square(tf.expand_dims(tf.expand_dims(x, 0), 2) - b)/(2*tf.square(c))\n",
    "    curves = -a*tf.exp(curves)\n",
    "\n",
    "    potentials = tf.reduce_sum(curves, -1, name=\"potentials\")\n",
    "\n",
    "    if return_x:\n",
    "        return potentials, x\n",
    "    else:\n",
    "        return potentials\n",
    "\n",
    "def generate_potentials(dataset_size=2000, points=500, n_gauss=3, length=1.0,\n",
    "                        a_minmax=(0.0, 3*10.0), b_minmax=(0.4, 0.6), c_minmax=(0.03, 0.1), return_x=False, seed=0):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        tf.set_random_seed(seed)\n",
    "        potentials, x = tf_generate_potentials(dataset_size, points, n_gauss, length,\n",
    "                                               a_minmax, b_minmax, c_minmax, return_x=True)\n",
    "        sess = tf.Session(graph=g)\n",
    "        np_potentials, np_x = sess.run([potentials, x])\n",
    "\n",
    "    if return_x:\n",
    "        return np_potentials, np_x\n",
    "    else:\n",
    "        return np_potentials\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"generating 1D gaussian mixture potential function:\")\n",
    "    print(\"M = 2000 ... dataset size\")\n",
    "    print(\"G = 500  ... discretization points of interval [0, 1]\")\n",
    "    print(\"negative sum of 3 gauss functions\")\n",
    "    print(\"random uniform amplitude (0, 10), mean (0.4, 0.6), and std (0.03, 0.1)\")\n",
    "    print(\"\")\n",
    "\n",
    "    np_potentials, np_x = generate_potentials(return_x=True)\n",
    "\n",
    "    print(\"potentials: \", np_potentials.shape, np_potentials.dtype)\n",
    "    print(\"x:\", np_x.shape, np_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculus_utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../quantumflow/calculus_utils.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def integrate(data, h, axis=-1):\n",
    "    if data.shape[axis] < 2:\n",
    "        raise ValueError(\n",
    "            \"Integration failed: time-axis {} has {} elements, required: >=2\".format(axis, data.shape[axis]))\n",
    "    return h * (np.sum(data, axis=axis) - 0.5 * (np.take(data, 0, axis=axis) + np.take(data, -1, axis=axis)))\n",
    "\n",
    "\n",
    "def integrate_simpson(data, h, axis=-1):\n",
    "    if data.shape[axis] < 2:\n",
    "        raise ValueError(\n",
    "            \"Integration failed: time-axis {} has {} elements, required: >=2\".format(axis, data.shape[axis]))\n",
    "    integral = 0\n",
    "    if not (data.shape[axis] > 2 and data.shape[axis] % 2 == 1):\n",
    "        integral = integrate(np.take(data, [-2, -1], axis=axis), h, axis)\n",
    "        if data.shape[axis] == 2:\n",
    "            return integral\n",
    "        data = np.take(data, range(0, data.shape[axis] - 1), axis=axis)\n",
    "\n",
    "    even = np.take(data, range(0, data.shape[axis], 2), axis=axis)\n",
    "    odd = np.take(data, range(1, data.shape[axis], 2), axis=axis)\n",
    "\n",
    "    return integral + h / 3 * (2 * np.sum(even, axis=axis) + 4 * np.sum(odd, axis=axis) - np.take(data, 0, axis=axis)\n",
    "                                                                                        - np.take(data, -1, axis=axis))\n",
    "\n",
    "\n",
    "def laplace(data, h):  # time_axis=1\n",
    "    temp_laplace = 1 / h ** 2 * (data[:, :-2, :] + data[:, 2:, :] - 2 * data[:, 1:-1, :])\n",
    "    return np.pad(temp_laplace, ((0, 0), (1, 1), (0, 0)), 'constant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numerov_solver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../quantumflow/numerov_solver.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from quantumflow.calculus_utils import integrate, integrate_simpson, laplace\n",
    "\n",
    "\n",
    "def unpack_dataset(N, dataset):\n",
    "    np_x, np_potentials, np_solutions, np_E = dataset\n",
    "    np_density = np.sum(np.square(np_solutions)[:, :, :N], axis=-1)\n",
    "    \n",
    "    dataset_size, discretization_points, _ = np_solutions.shape\n",
    "    h = (max(np_x) - min(np_x))/(discretization_points-1)\n",
    "    \n",
    "    np_potential = np.expand_dims(np_potentials, axis=2)*np_solutions**2\n",
    "    np_P = integrate_simpson(np_potential, h, axis=1)\n",
    "    np_K = np_E - np_P\n",
    "\n",
    "    kinetic_energy = np.sum(np_K[:, :N], axis=-1)\n",
    "    \n",
    "    return np_x, np_potentials, np_solutions, np_E, np_density, kinetic_energy, dataset_size, discretization_points, h    \n",
    "\n",
    "\n",
    "# recurrent tensorflow cell for solving the numerov equation recursively\n",
    "class ShootingNumerovCell(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, h=1.0):\n",
    "        super().__init__()\n",
    "        self._h2_scaled = 1 / 12 * h ** 2\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        k_m2, k_m1, y_m2, y_m1 = tf.unstack(state, axis=-1)\n",
    "\n",
    "        y = (2 * (1 - 5 * self._h2_scaled * k_m1) * y_m1 - (1 + self._h2_scaled * k_m2) * y_m2) / (\n",
    "                    1 + self._h2_scaled * inputs)\n",
    "\n",
    "        new_state = tf.stack([k_m1, inputs, y_m1, y], axis=-1)\n",
    "        return y, new_state\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return 4\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return 1\n",
    "\n",
    "# tf function for using the shooting numerov method\n",
    "#\n",
    "# the init_factor is the slope of the solution at x=0\n",
    "# it can be constant>0 because it's actual value will be determined when the wavefunction is normalized\n",
    "#\n",
    "def shooting_numerov(k_squared, h=1, init_factor=1e-128):\n",
    "    shooting_cell = ShootingNumerovCell(h=h)\n",
    "    init_state = tf.stack([k_squared[:, 0], k_squared[:, 1], tf.zeros_like(k_squared[:, 2]),\n",
    "                           init_factor * h * tf.ones_like(k_squared[:, 3])], axis=-1)\n",
    "    outputs, _ = tf.nn.static_rnn(shooting_cell, tf.unstack(k_squared, axis=1)[2:], initial_state=init_state)\n",
    "    output = tf.stack([init_state[:, 2], init_state[:, 3]] + outputs, axis=-1)\n",
    "    return output\n",
    "\n",
    "# returns the rearranged schroedinger equation term in the numerov equation\n",
    "# k_squared = 2*m_e/h_bar**2*(E - V(x))\n",
    "def numerov_k_squared(potentials, energies):\n",
    "    return 2 * (np.expand_dims(energies, axis=1) - np.repeat(np.expand_dims(potentials, axis=2), energies.shape[1], axis=2))\n",
    "\n",
    "\n",
    "def detect_roots(array1):\n",
    "    return np.logical_or(array1[:, 1:] == 0, array1[:, 1:] * array1[:, :-1] < 0)\n",
    "\n",
    "\n",
    "class NumerovSolver():\n",
    "    def __init__(self, G, h):\n",
    "        self.K_SQUARED = tf.placeholder(tf.float64, shape=(None, G))\n",
    "        self.solution = shooting_numerov(self.K_SQUARED, h=h)\n",
    "        self.sess = tf.Session()\n",
    "        self.h = h\n",
    "        self.G = G\n",
    "        \n",
    "    # functtion to solve the shooting numerov equation for a given tensor of k_squared functions\n",
    "    # the tensor has to have one dimension for the time along wich to solve the equation\n",
    "    # all other dimensions will be flattened internally but the return value will be reshaped back\n",
    "    def run_numerov(self, k_squared, time_axis=-1):\n",
    "        shape = k_squared.shape[:time_axis] + k_squared.shape[time_axis + 1:]\n",
    "        flattened = np.reshape(np.moveaxis(k_squared, time_axis, -1), (-1, k_squared.shape[time_axis]))\n",
    "        flattened_solutions = self.sess.run(self.solution, feed_dict={self.K_SQUARED: flattened})\n",
    "        solutions = np.reshape(flattened_solutions, shape + (k_squared.shape[time_axis],))\n",
    "        return np.moveaxis(solutions, -1, time_axis)\n",
    "\n",
    "    \n",
    "    def solve_numerov(self, np_potentials, target_roots, split_energies, progress=None):\n",
    "\n",
    "        np_E_low = split_energies[:, :-1].copy()\n",
    "        np_E_high = split_energies[:, 1:].copy()\n",
    "\n",
    "        # because the search interval is halved at every step\n",
    "        # 32 iterations will always converge to the best numerically possible accuracy of E\n",
    "        # (empirically ~25 steps)\n",
    "\n",
    "        np_E = 0.5 * (np_E_low + np_E_high)\n",
    "        np_E_last = np.copy(np_E) * 2\n",
    "\n",
    "        \n",
    "        if progress is not None:\n",
    "            progress.value = 0\n",
    "            progress.max = np.prod(np_E.shape)\n",
    "            progress.description = 'Numerov Pass: '\n",
    "        \n",
    "        step = 0\n",
    "        while np.any(np_E_last - np_E):\n",
    "            np_V = numerov_k_squared(np_potentials, np_E)\n",
    "            np_solutions = self.run_numerov(np_V, time_axis=1)\n",
    "            np_roots = np.sum(detect_roots(np_solutions), axis=1)\n",
    "\n",
    "            np_E_low[np_roots <= target_roots] = np_E[np_roots <= target_roots]\n",
    "            np_E_high[np_roots > target_roots] = np_E[np_roots > target_roots]\n",
    "\n",
    "            np_E_last = np_E\n",
    "            np_E = 0.5 * (np_E_low + np_E_high)\n",
    "\n",
    "            if progress is not None:\n",
    "                progress.value = progress.max - np.sum(np_E_last - np_E != 0)\n",
    "                progress.description = 'Numerov Pass: ' + str(progress.value) + '/' + str(progress.max)\n",
    "            step += 1\n",
    "\n",
    "        np_solutions_low = self.run_numerov(numerov_k_squared(np_potentials, np_E_low), time_axis=1)\n",
    "        np_roots_low = 1 * detect_roots(np_solutions_low)\n",
    "\n",
    "        np_solutions_high = self.run_numerov(numerov_k_squared(np_potentials, np_E_high), time_axis=1)\n",
    "        np_roots_high = 1 * detect_roots(np_solutions_high)\n",
    "\n",
    "        np_roots_diff = np.abs(np_roots_high - np_roots_low)  # useless but keep it\n",
    "        # assert(np.all(np.sum(np_roots_diff, axis=1) == 1)) # sometimes roots are at different places!\n",
    "\n",
    "        np_nan_cumsum = np.cumsum(np.pad(np_roots_diff, ((0, 0), (1, 0), (0, 0)), 'constant'), axis=1)\n",
    "        np_nan_index = np_nan_cumsum == np.expand_dims(np_nan_cumsum[:, -1], axis=1)\n",
    "\n",
    "        np_solutions_low[np_nan_index] = np.nan\n",
    "\n",
    "        return np_solutions_low, np_E, step\n",
    "\n",
    "    \n",
    "    def find_split_energies(self, np_potentials, N, progress=None):\n",
    "        M = np_potentials.shape[0]\n",
    "        \n",
    "        # Knotensatz: number of roots = quantum state\n",
    "        # so target root = target excited state quantum number\n",
    "        target_roots = np.repeat(np.expand_dims(np.arange(N + 1), axis=0), M, axis=0)\n",
    "\n",
    "        # lowest value of potential as lower bound\n",
    "        np_E_split = np.repeat(np.expand_dims(np.min(np_potentials, axis=1), axis=1), N + 1, axis=1)\n",
    "\n",
    "        np_solutions_split = np.zeros((np_potentials.shape[0], np_potentials.shape[1], N + 1), dtype=np.float64)\n",
    "        not_converged = np.ones(np_potentials.shape[0], dtype=np.bool)\n",
    "        search_boost = np.ones_like(np_E_split)\n",
    "        np_E_delta = np.ones_like(np_E_split)\n",
    "\n",
    "        if progress is not None:\n",
    "            progress.value = 0\n",
    "            progress.max = M\n",
    "            progress.description = 'Searching Roots:'\n",
    "\n",
    "        step = 0\n",
    "        while np.any(not_converged):\n",
    "            np_V_split = numerov_k_squared(np_potentials[not_converged], np_E_split[not_converged])\n",
    "            np_solutions_split[not_converged] = self.run_numerov(np_V_split, time_axis=1)\n",
    "            np_roots_split = np.sum(detect_roots(np_solutions_split), axis=1)\n",
    "\n",
    "            not_converged[np.all(np_roots_split == target_roots, axis=1)] = False\n",
    "\n",
    "            search_direction = 1 * (np_roots_split < target_roots) - 1 * (np_roots_split > target_roots)\n",
    "            np_E_delta[np.logical_and(search_direction == np.sign(np_E_delta), search_boost)] *= 2\n",
    "            search_boost[search_direction * np.sign(np_E_delta) < 0] = 0\n",
    "            np_E_delta[search_direction * np.sign(np_E_delta) < 0] *= -0.5\n",
    "\n",
    "            np_E_split[not_converged] += np_E_delta[not_converged]\n",
    "\n",
    "            if progress is not None:\n",
    "                progress.value = progress.max - np.sum(not_converged)\n",
    "                progress.description = 'Searching Roots: ' + str(progress.value) + '/' + str(progress.max)\n",
    "            step += 1\n",
    "\n",
    "        return np_E_split, step\n",
    "\n",
    "    \n",
    "    def solve_schroedinger(self, np_potentials, N, progress=None):\n",
    "        M = np_potentials.shape[0]\n",
    "        G = np_potentials.shape[1]\n",
    "        \n",
    "        assert (G == self.G)\n",
    "        np_E_split, _ = self.find_split_energies(np_potentials, N, progress=progress)\n",
    "\n",
    "        target_roots = np.repeat(np.expand_dims(np.arange(N), axis=0), M, axis=0)\n",
    "        np_solutions_forward, np_E_forward, _ = self.solve_numerov(np_potentials, target_roots, np_E_split, progress=progress)\n",
    "        np_solutions_forward /= np.expand_dims(np.nanmax(np.abs(np_solutions_forward), axis=1), axis=1)\n",
    "\n",
    "        assert not np.any(np.all(np.isnan(np_solutions_forward), axis=1))\n",
    "\n",
    "        np_solutions_backward, np_E_backward, _ = self.solve_numerov(np.flip(np_potentials, axis=1), target_roots, np_E_split, progress=progress)\n",
    "        np_solutions_backward = np.flip(np_solutions_backward, axis=1)\n",
    "        np_solutions_backward /= np.expand_dims(np.nanmax(np.abs(np_solutions_backward), axis=1), axis=1)\n",
    "\n",
    "        assert not np.any(np.all(np.isnan(np_solutions_backward), axis=1))\n",
    "\n",
    "        np_factor = np_solutions_forward / np_solutions_backward\n",
    "\n",
    "        assert not np.any(np.all(np.isnan(np_factor), axis=1))\n",
    "\n",
    "        np_solutions_backward *= np.expand_dims(np.nanmedian(np_factor, axis=1), axis=1)\n",
    "\n",
    "        join_error = np.nanmin(np.abs(np_solutions_backward - np_solutions_forward), axis=1)\n",
    "\n",
    "        join_error = np.nanmax(np_solutions_backward / np_solutions_forward, axis=1)\n",
    "\n",
    "        join_index = np.nanargmin(np.abs(np_solutions_backward - np_solutions_forward), axis=1)\n",
    "\n",
    "        join_mask = np.expand_dims(np.expand_dims(np.arange(np_solutions_backward.shape[1]), axis=0), axis=2) >= np.expand_dims(join_index, axis=1)\n",
    "\n",
    "        np_solutions = np_solutions_forward\n",
    "        np_solutions[join_mask] = np_solutions_backward[join_mask]\n",
    "\n",
    "        # normalization\n",
    "        np_norm = np_solutions ** 2\n",
    "        np_norm = integrate_simpson(np_norm, self.h, axis=1)\n",
    "        np_solutions *= 1 / np.sqrt(np.expand_dims(np_norm, axis=1))\n",
    "\n",
    "        assert not np.any(np.all(np.isnan(np_solutions), axis=1))\n",
    "        \n",
    "        np_E = 0.5*(np_E_forward + np_E_backward)\n",
    "        \n",
    "        return np_E, np_solutions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from quantumflow.generate_potentials import generate_potentials\n",
    "from quantumflow.calculus_utils import integrate, integrate_simpson, laplace\n",
    "from quantumflow.numerov_solver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_parameters(dataset_name):  \n",
    "    seed = 0\n",
    "    \n",
    "    if \"recreate\" in dataset_name:\n",
    "        N = 4 # number of electrons\n",
    "        \n",
    "        M = dataset_size = 2000 # train dataset size\n",
    "        M_val = M # validation dataset size\n",
    "        M_test = M # test dataset size\n",
    "        \n",
    "        G = points = 500 # discretization points\n",
    "        length = 1.0 # [Bohr]\n",
    "\n",
    "        n_gauss = 3\n",
    "        a_minmax = (1.0, 10.0) # [hartree] \n",
    "        b_minmax = (0.4, 0.6) # nomalized x\n",
    "        c_minmax = (0.03, 0.1) # normalized x\n",
    "\n",
    "        # recreate/fine_n\n",
    "        if \"fine\" in dataset:\n",
    "            factor = float(dataset.split('_')[-1])\n",
    "            G = points = int((500-1)*factor+1)\n",
    "            M_val = 0\n",
    "            M_test = 0\n",
    "\n",
    "    elif \"standard\" in dataset_name:\n",
    "        N = 4 # number of electrons\n",
    "        \n",
    "        M = dataset_size = 5000 # train dataset size\n",
    "        M_val = M # validation dataset size\n",
    "        M_test = M # test dataset size\n",
    "        \n",
    "        G = points = 1001 # discretization points\n",
    "        length = 20.0 # [Bohr]\n",
    "\n",
    "        n_gauss = 5\n",
    "        a_minmax = (0.0/n_gauss, 50.0/n_gauss) # [hartree] \n",
    "        b_minmax = (.3, 0.7) # nomalized x\n",
    "        c_minmax = (.02, 0.06) # normalized x\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"dataset parameters for name '{}' not defined.\".format(dataset_name))\n",
    "        \n",
    "    return M, M_val, M_test, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core part of this file:\n",
    "change the datasets variable for creating different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "datasets = [\"recreate\", \"standard\"] # + [\"recreate/fine_\" + str(factor) for factor in [0.125, 0.25, 0.5, 1, 2, 5, 8, 10]]\n",
    "\n",
    "progress = widgets.IntProgress(value=0, max=0, description='init...', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        M, M_val, M_test, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax = dataset_parameters(dataset)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    directory = os.path.join(datadir, dataset)\n",
    "    if not os.path.exists(os.path.join(datadir, dataset)):\n",
    "            os.makedirs(os.path.join(datadir, dataset))\n",
    "\n",
    "    for dataset_size, extension in zip([M, M_val, M_test], [\"_training\", \"_validation\", \"_testing\"]):\n",
    "\n",
    "        np_potentials, np_x = generate_potentials(dataset_size=dataset_size, points=G, n_gauss=n_gauss, length=length,\n",
    "                                                  a_minmax=a_minmax, b_minmax=b_minmax, c_minmax=c_minmax, \n",
    "                                                  return_x=True, seed=seed)\n",
    "\n",
    "        h = (max(np_x) - min(np_x))/(G-1)\n",
    "\n",
    "        np_E, np_solutions = NumerovSolver(G, h).solve_schroedinger(np_potentials, N, progress=progress)\n",
    "        \n",
    "        filename = 'dataset' + extension + '.pkl'\n",
    "        with open(os.path.join(directory, filename), 'wb') as f:\n",
    "            pickle.dump([np_x, np_potentials, np_solutions, np_E], f)\n",
    "\n",
    "        print(\"dataset\", filename, \"saved to\", directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"standard\"\n",
    "M, _, _, G, N, length, seed, n_gauss, a_minmax, b_minmax, c_minmax = dataset_parameters(dataset)\n",
    "\n",
    "print(\"Dataset:\", dataset)\n",
    "print(\"\")\n",
    "print(\"dataset size M:\", M)\n",
    "print(\"discretiation points G:\", G)\n",
    "print(\"1D box length:\", length, 'bohr')\n",
    "print(\"\")\n",
    "print(\"potential function parameters:\")\n",
    "print(\"seed:\", seed)\n",
    "print(\"number of gaussian functions:\", n_gauss)\n",
    "print(\"a uniform: \", list(a_minmax))\n",
    "print(\"b uniform: \", list(b_minmax))\n",
    "print(\"c uniform: \", list(c_minmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_potentials, np_x = generate_potentials(dataset_size=M, points=G, n_gauss=n_gauss, length=length,\n",
    "                                          a_minmax=a_minmax, b_minmax=b_minmax, c_minmax=c_minmax, \n",
    "                                          return_x=True, seed=seed)\n",
    "h = (max(np_x) - min(np_x))/(G-1) # discretization width [bohr]\n",
    "\n",
    "preview = 5\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np_x, np.transpose(np_potentials)[:, :preview]) # only plot first potentials\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "solver = NumerovSolver(G, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "split_energies, steps = solver.find_split_energies(np_potentials, N, progress=progress)\n",
    "print(\"found all split energies in\", steps, \"steps\")\n",
    "print(\"shape:\", split_energies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "bins = np.linspace(min(split_energies.flatten()), max(split_energies.flatten()), 100)\n",
    "\n",
    "for i in range(split_energies.shape[1]):\n",
    "    plt.hist(split_energies[:, i], bins, alpha=0.7, label=\" < E_\" + str(i))\n",
    "\n",
    "plt.xlabel('split energy / hartree')\n",
    "plt.ylabel('count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Energies giving the intervals where there is exactly one eigenvalue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "target_roots = np.repeat(np.expand_dims(np.arange(N), axis=0), M, axis=0)\n",
    "np_solutions_forward, np_E_forward, steps = solver.solve_numerov(np_potentials, target_roots, split_energies, progress=progress)\n",
    "np_solutions_forward /= np.expand_dims(np.nanmax(np.abs(np_solutions_forward), axis=1), axis=1)\n",
    "print(\"steps to convergence: \", steps)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions_forward), axis=1))\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Numerov Forward Pass Solutions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = widgets.IntProgress(value=0, max=np_potentials.shape[0], description='Searching:', bar_style='info', layout=widgets.Layout(width='92%'))\n",
    "display(progress)\n",
    "\n",
    "np_solutions_backward, np_E_backward, steps = solver.solve_numerov(np.flip(np_potentials, axis=1), target_roots, split_energies, progress=progress)\n",
    "np_solutions_backward = np.flip(np_solutions_backward, axis=1)\n",
    "np_solutions_backward /= np.expand_dims(np.nanmax(np.abs(np_solutions_backward), axis=1), axis=1)\n",
    "print(\"steps to convergence: \", steps)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions_backward), axis=1))\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_backward[:preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "    plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Numerov Backward Pass Solutions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_factor = np_solutions_forward/np_solutions_backward\n",
    "np_median = np.nanmedian(np_factor, axis=1)\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_factor), axis=1))\n",
    "\n",
    "\n",
    "merge_preview = 1\n",
    "merge_preview_n_max = 4\n",
    "\n",
    "fig, axs = plt.subplots(N, 1, figsize=(20, 8))\n",
    "for i, np_plot in enumerate(np_factor[:merge_preview]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        axs[n].plot(np_x, np.ones(np_x.shape)*np_median[i, n], 'r', label=\"median\")\n",
    "        axs[n].plot(np_x, np_plot_single, 'C' + str(i%10), label=\"forward/backward\")\n",
    "        if n == 0: axs[n].legend(loc='best')\n",
    "fig.suptitle('Factor between forward an backward pass, should be 1.0, some spikes near zeroes of the wavefunction, median as red line')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_solutions_backward_scaled = np_solutions_backward*np.expand_dims(np_median, axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_backward_scaled[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.title('Scaled backwards pass with forward pass. Now they have equal signs and should match nicely for the most part')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions_forward[:merge_preview] - np_solutions_backward_scaled[:merge_preview]):\n",
    "    plt.plot(np_x, np_plot, 'C' + str(i%10))\n",
    "plt.xlim(np_x[[0, -1]])\n",
    "plt.title('Difference in forward and backward pass')\n",
    "plt.show()\n",
    "\n",
    "join_error = np.nanmax(np.abs(np_solutions_backward_scaled - np_solutions_forward), axis=1)\n",
    "print(\"maximal absolute errors:\")\n",
    "print(join_error[:merge_preview])\n",
    "print(\"dataset maximal absolute error:\", np.max(join_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_index = np.nanargmin(np.abs(np_solutions_backward_scaled - np_solutions_forward), axis=1)\n",
    "join_mask = np.expand_dims(np.expand_dims(np.arange(np_solutions_backward_scaled.shape[1]), axis=0), axis=2) >= np.expand_dims(join_index, axis=1)\n",
    "\n",
    "np_solutions = np_solutions_forward.copy()\n",
    "np_solutions[join_mask] = np_solutions_backward_scaled[join_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_plot in enumerate(np_solutions[:merge_preview]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        plt.plot(np_x[:join_index[i, n]], np_solutions_forward[i, :join_index[i, n], n], 'g')\n",
    "        plt.plot(np_x[join_index[i, n]-1:], np_solutions_backward_scaled[i, join_index[i, n]-1:, n], 'b')\n",
    "plt.legend(['forward', 'backward'])\n",
    "plt.title('Merged wavefunctions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "np_norm = np_solutions**2\n",
    "np_norm = integrate_simpson(np_norm, h, axis=1)\n",
    "np_solutions *= 1/np.sqrt(np.expand_dims(np_norm, axis=1))\n",
    "\n",
    "assert not np.any(np.all(np.isnan(np_solutions), axis=1))\n",
    "\n",
    "print('max energy error:', np.max(np_E_forward - np_E_backward))\n",
    "np_E = 0.5*(np_E_forward + np_E_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, preview, figsize=(20, 8))\n",
    "for i, np_plot in enumerate(np_solutions[:preview]**2 + np_E[:preview, np.newaxis, :]):\n",
    "    for n, np_plot_single in enumerate(np_plot.transpose()):\n",
    "        axs[i].plot(np_x, np_potentials[i], 'k')\n",
    "        axs[i].plot(np_x, np.ones(np_x.shape)*np_E[i, n], ':k')\n",
    "        axs[i].plot(np_x, np_plot_single, 'C' + str(i%10))\n",
    "        axs[i].set_ylim([np.min(np_potentials[:preview]), max(np.max(np_E[:preview]*1.1), 0.5)])\n",
    "        if i == 0: axs[i].set_ylabel('energies, potential / hartree')\n",
    "fig.suptitle('Numerov Solution Energies and Densities')\n",
    "plt.show()\n",
    "print('\\neigenvalue energies:\\n', np_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_density = np.sum(np_solutions**2, axis=-1)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.plot(np_x, np.transpose(np_potentials)[:, :preview])\n",
    "plt.title('Potential V')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_density_group in enumerate(np_density[:preview]):\n",
    "    plt.plot(np_x, np_density_group, 'C' + str(i%10))\n",
    "plt.title('Total Density N=' + str(N))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_laplace = laplace(np_solutions, h)\n",
    "np_kinetic = -0.5*np_solutions*np_laplace\n",
    "np_K = integrate_simpson(np_kinetic, h, axis=1)\n",
    "np_potential = np.expand_dims(np_potentials, axis=2)*np_solutions**2\n",
    "np_P = integrate_simpson(np_potential, h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_solutions_group in enumerate(np_solutions[:preview]):\n",
    "    plt.plot(np_x, np_solutions_group, 'C' + str(i%10))\n",
    "plt.title('Wavefunctions')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_laplace_group in enumerate(np_laplace[:preview]):\n",
    "    plt.plot(np_x, np_laplace_group, 'C' + str(i%10))\n",
    "plt.title('Laplace(Wavefunction)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_kinetic_group in enumerate(np_kinetic[:preview]):\n",
    "    plt.plot(np_x, np_kinetic_group, 'C' + str(i%10))\n",
    "plt.title('Kinetic Energy Density')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, np_potential_group in enumerate(np_potential[:preview]):\n",
    "    plt.plot(np_x, np_potential_group, 'C' + str(i%10))\n",
    "plt.title('Potential Energy Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy = np.sum(np_E, axis=-1)\n",
    "print('total energy:', total_energy)\n",
    "\n",
    "potential_energy = np.sum(np_P, axis=-1)\n",
    "print('potential energy:', potential_energy)\n",
    "\n",
    "kinetic_energy = np.sum(np_K, axis=-1)\n",
    "print('kinetic energy direct:', kinetic_energy)\n",
    "\n",
    "np_K_id = np_E - np_P\n",
    "kinetic_energy_id = np.sum(np_K_id, axis=-1)\n",
    "print('kinetic energy indirect:', kinetic_energy_id)\n",
    "\n",
    "assert(not np.any(np.isnan(np_density)))\n",
    "assert(not np.any(np.isnan(np_kinetic)))\n",
    "assert(not np.any(np.isnan(kinetic_energy)))\n",
    "assert(not np.any(np.isnan(kinetic_energy_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0_generate_datasets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
