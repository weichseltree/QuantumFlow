{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup notebook if it is run on Google Colab, cwd = notebook file location\n",
    "try:\n",
    "    # change notebook_path if this notebook is in a different subfolder of Google Drive\n",
    "    notebook_path = \"Projects/QuantumFlow/notebooks\"\n",
    "\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(\"/content/gdrive/My Drive/\" + notebook_path)\n",
    "\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q ruamel.yaml\n",
    "\n",
    "    %load_ext tensorboard\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# setup paths and variables for shared code (../quantumflow) and data (../data)\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "data_dir = \"../data\"\n",
    "\n",
    "# import shared code, must run 0_create_shared_project_files.ipynb first!\n",
    "from quantumflow.utils import load_hyperparameters, train, build_model, QFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'models'\n",
    "\n",
    "base_dir = os.path.join(data_dir, experiment)\n",
    "figures_dir = os.path.join(data_dir, 'models/figures')\n",
    "if not os.path.exists(figures_dir): os.makedirs(figures_dir)\n",
    "\n",
    "figsize = (10, 3)\n",
    "dpi=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=$base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['cnn',\n",
    "          'resnet',\n",
    "          'resnet_vW_N2',\n",
    "          'models_large/resnet_vW_N2_1000',\n",
    "          'models_large/resnet_vW_N2_10000',\n",
    "          'models_large/resnet_vW_N2_100000']\n",
    "\n",
    "model_params = {model: load_hyperparameters(os.path.join(base_dir, 'models_large'*model.startswith('models_large') , \"hyperparams.config\"), run_name=model.replace('models_large/', '')) for model in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{model: params['model_kwargs']['l2_regularisation'] for model, params in model_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import pandas as pd \n",
    "\n",
    "def load_summaries(event_dir):\n",
    "    summaries = {}\n",
    "\n",
    "    assert os.path.exists(event_dir), event_dir\n",
    "\n",
    "    event_files = [os.path.join(event_dir, file) for file in os.listdir(event_dir) if '.tfevents' in file]\n",
    "\n",
    "    assert len(event_files) > 0, event_dir\n",
    "\n",
    "    def create_or_append(tag, step, wall_time, keys, values):\n",
    "        try:\n",
    "            if step not in summaries[tag]['step']:\n",
    "                summaries[tag]['step'].append(step)\n",
    "                #summaries[tag]['wall_time'].append(wall_time)\n",
    "                if isinstance(keys, list):\n",
    "                    for key, value in zip(keys, values):\n",
    "                        summaries[tag][key].append(value)\n",
    "                else:\n",
    "                    summaries[tag][keys].append(values)\n",
    "        except KeyError:\n",
    "            summaries[tag] = {'step': [step]}#, 'wall_time': [wall_time]}\n",
    "            if isinstance(keys, list):\n",
    "                for key, value in zip(keys, values):\n",
    "                    summaries[tag][key] = [value]\n",
    "            else:\n",
    "                summaries[tag][keys] = [values]\n",
    "            \n",
    "    for event_file in event_files:\n",
    "        for summary in summary_iterator(event_file):\n",
    "            if summary.summary.value.__len__() == 0: continue   \n",
    "\n",
    "            for entry in summary.summary.value:\n",
    "                if entry.tag == 'keras':\n",
    "                    continue # model config\n",
    "                elif 'bias' in entry.tag or 'kernel' in entry.tag: \n",
    "                    if 'image' in entry.tag:\n",
    "                        create_or_append('image/' + entry.tag.replace('image/', ''), summary.step, summary.wall_time, entry.tag.replace('image/', ''), entry.image.encoded_image_string)\n",
    "                    else:\n",
    "                        continue #histograms\n",
    "                else: # metrics\n",
    "                    create_or_append(entry.tag, summary.step, summary.wall_time, 'simple_value', entry.simple_value)\n",
    "                \n",
    "    for key in summaries.keys():\n",
    "        summaries[key] = pd.DataFrame(data=summaries[key]).set_index('step')\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfevents_dir = {model: os.path.join(base_dir, model, 'train') for model in models}\n",
    "model_summaries = {model: load_summaries(tfevents_dir) for model, tfevents_dir in train_tfevents_dir.items()}\n",
    "model_summaries['resnet'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = {model: model.replace('models_large/', '').replace('_1', '').replace('0', '') + ' (M: {}, {} epochs)'.format(100 if model_params[model]['fit_kwargs']['epochs'] == 100000 else int(30000000/model_params[model]['fit_kwargs']['epochs']), model_params[model]['fit_kwargs']['epochs']) for model in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "for model, summary in model_summaries.items():\n",
    "    plt.plot(summary['learning_rate']['simple_value'].index/model_params[model]['fit_kwargs']['epochs']*(100000 if model_params[model]['fit_kwargs']['epochs'] == 100000 else 300000), summary['learning_rate'], label=model_labels[model])\n",
    "plt.grid()\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.ylabel('learning rate')\n",
    "plt.xlabel('training step')\n",
    "plt.savefig(os.path.join(figures_dir, 'learning_rate.eps'), format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "for model, summary in model_summaries.items():\n",
    "    plt.plot(summary['learning_rate']['simple_value'].index/model_params[model]['fit_kwargs']['epochs'], summary['loss'], label=model_labels[model])\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('training progress')\n",
    "plt.savefig(os.path.join(figures_dir, 'loss.eps'), format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "for model, summary in model_summaries.items():\n",
    "    plt.plot(summary['learning_rate']['simple_value'].index/model_params[model]['fit_kwargs']['epochs'], summary['mean_absolute_error/kinetic_energy'], label=model_labels[model])\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('mean absolute error / hartree')\n",
    "plt.xlabel('training progress')\n",
    "plt.savefig(os.path.join(figures_dir, 'kinetic_energy.eps'), format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "for model, summary in model_summaries.items():\n",
    "    plt.plot(summary['learning_rate']['simple_value'].index/model_params[model]['fit_kwargs']['epochs'], summary['mean_absolute_error/derivative'], label=model_labels[model])\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('mean absolute error / hartree')\n",
    "plt.xlabel('training progress')\n",
    "plt.savefig(os.path.join(figures_dir, 'derivative.eps'), format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "for model, summary in model_summaries.items():\n",
    "    if 'mean_absolute_error/kinetic_energy_density' in summary:\n",
    "        plt.plot(summary['learning_rate']['simple_value'].index/model_params[model]['fit_kwargs']['epochs'], summary['mean_absolute_error/kinetic_energy_density'], label=model_labels[model])\n",
    "    else:\n",
    "        plt.plot([], [], label='')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('mean absolute error / hartree')\n",
    "plt.xlabel('training progress')\n",
    "plt.savefig(os.path.join(figures_dir, 'kinetic_energy_density.eps'), format='eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMRw90aJSu8U8Svx4jwFRI",
   "collapsed_sections": [],
   "name": "5_figures.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
