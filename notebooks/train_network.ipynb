{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.DEBUG)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install -q ruamel.yaml\n",
    "    !pip install -q tensorboard-plugin-profile\n",
    "    project_path = '/content/drive/MyDrive/Colab Projects/QuantumFlow'\n",
    "except:\n",
    "    project_path = os.path.expanduser('~/QuantumFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_path)\n",
    "sys.path.append(project_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "\n",
    "import quantumflow\n",
    "\n",
    "experiment = 'xdiff_perciever'\n",
    "run_name = 'debug_input'\n",
    "\n",
    "base_dir = os.path.join(project_path, \"experiments\", experiment)\n",
    "params = quantumflow.utils.load_yaml(os.path.join(base_dir, 'hyperparams.yaml'))[run_name]\n",
    "run_dir = os.path.join(base_dir, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %tensorboard --logdir=\"$base_dir\" --load_fast=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = quantumflow.instantiate(params['dataset_train'], run_dir=run_dir)\n",
    "dataset_train.build()\n",
    "\n",
    "dataset_validate = quantumflow.instantiate(params['dataset_validate'], run_dir=run_dir)\n",
    "dataset_validate.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.profiler.experimental.server.start(6009)\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(params['seed'])\n",
    "\n",
    "model = quantumflow.instantiate(params['model'], run_dir=run_dir, dataset=dataset_train)\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for var in model.variables:\n",
    "    print(f\"{np.prod(var.shape):<5d}\", var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = quantumflow.instantiate(params['optimizer'])\n",
    "\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    loss=params['loss'], \n",
    "    loss_weights=params.get('loss_weights', None), \n",
    "    metrics=params.get('metrics', None)\n",
    ")\n",
    "\n",
    "\n",
    "if params.get('load_checkpoint', None) is not None:\n",
    "    model.load_weights(os.path.join(data_dir, params['load_checkpoint']))\n",
    "    if params['fit'].get('verbose', 0) > 0:\n",
    "        print(\"loading weights from \", os.path.join(data_dir, params['load_checkpoint']))\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "\n",
    "if run_dir is not None and params.get('checkpoint', False):\n",
    "    checkpoint_params = params['checkpoint'].copy()\n",
    "    checkpoint_params['filepath'] = os.path.join(run_dir, checkpoint_params.pop('filename', 'weights.{epoch:05d}.hdf5'))\n",
    "    checkpoint_params['verbose'] = checkpoint_params.get('verbose', min(1, params['fit'].get('verbose', 1)))\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(**checkpoint_params))\n",
    "\n",
    "\n",
    "if 'tensorboard' in params:\n",
    "    callbacks.append(\n",
    "        quantumflow.instantiate(params['tensorboard'], log_dir=run_dir, learning_rate=optimizer.learning_rate))\n",
    "\n",
    "\n",
    "model.fit(x=dataset_train.features, \n",
    "          y=dataset_train.targets, \n",
    "          callbacks=callbacks,\n",
    "          validation_data=(dataset_validate.features, dataset_validate.targets) if dataset_validate is not None else None,\n",
    "          **params['fit'])\n",
    "\n",
    "if params['save'] is True:\n",
    "    save_model = getattr(model, params['save_model']) if not params.get('save_model', 'self') == 'self' else model\n",
    "    save_model.save(os.path.join(run_dir, 'saved_model'), include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantumflow.utils import anim_plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = tree.map_structure(lambda feature: feature[0:1], dataset_validate.features)\n",
    "sample_targets = tree.map_structure(lambda target: target[0:1], dataset_validate.targets)\n",
    "sample_targets_pred = model(sample_features)\n",
    "sample = tree.map_structure(lambda target, target_pred: (target[0], target_pred.numpy()[0]), sample_targets, sample_targets_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_path, (target, target_pred) in tree.flatten_with_path_up_to(sample_targets, sample):\n",
    "    target_name = '/'.join(target_path)\n",
    "    \n",
    "    if np.squeeze(target).shape == dataset_validate.x.shape:\n",
    "\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(dataset_train.x, target, 'k')\n",
    "        plt.plot(dataset_train.x, np.squeeze(target_pred))\n",
    "        plt.title(target_name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{target_name}: {target_pred} ({target})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = model.layers[0](sample_features)\n",
    "x, x_inputs, inputs = model.layers[1](latents['density'])\n",
    "x = model.layers[2](x)\n",
    "latents, xdiff, inputs, xdiff_cross, layers = model.layers[3].get_core(x, x_inputs, inputs)\n",
    "\n",
    "for self in layers:\n",
    "    print(self.name)\n",
    "    if 'encoder' in self.name:\n",
    "        if 'cross' in self.name:\n",
    "            lat = self.layernorm1a(latents)\n",
    "            inp = self.layernorm1b(inputs)\n",
    "                \n",
    "            for i in range(lat.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(lat[0, :, i, :])\n",
    "                plt.title('Normalized Latents')\n",
    "                plt.show()\n",
    "                \n",
    "            plt.figure(figsize=(20, 3))\n",
    "            plt.plot(inp[0, 0, :, :])\n",
    "            plt.title('Normalized Inputs')\n",
    "            plt.show()\n",
    "            \n",
    "            attn_output, _ = self.mha(lat, inp, inp, xdiff_cross, mask=None)  # (..., latent_size, d_model)\n",
    "\n",
    "            for i in range(attn_output.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(attn_output[0, :, i, :])\n",
    "                plt.title('Attention Output')\n",
    "                plt.show()\n",
    "                \n",
    "            attn_output = self.dropout1(attn_output, training=True)\n",
    "            \n",
    "            latents = latents + attn_output\n",
    "            \n",
    "            for i in range(latents.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(latents[0, :, i, :])\n",
    "                plt.title('Skip Attn Output')\n",
    "                plt.show()\n",
    "                \n",
    "            lat = self.layernorm2(latents)  # (..., latent_size, d_model)\n",
    "            ffn_output = self.ffn(lat)  # (..., latent_size, d_model)\n",
    "            ffn_output = self.dropout2(ffn_output, training=True)\n",
    "\n",
    "            latents = latents + ffn_output\n",
    "            \n",
    "            for i in range(latents.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(latents[0, :, i, :])\n",
    "                plt.title('Skip FFN Output')\n",
    "                plt.show()\n",
    "                \n",
    "        else:\n",
    "            lat = self.layernorm1(latents)  # (..., input_size, d_model)\n",
    "                \n",
    "            for i in range(lat.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(lat[0, :, i, :])\n",
    "                plt.title('Normalized Latents')\n",
    "                plt.show()\n",
    "\n",
    "            attn_output, _ = self.mha(lat, lat, lat, xdiff, mask=None)  # (..., input_size, d_model)\n",
    "\n",
    "            for i in range(attn_output.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(attn_output[0, :, i, :])\n",
    "                plt.title('Attention Output')\n",
    "                plt.show()\n",
    "                \n",
    "            attn_output = self.dropout1(attn_output, training=True)\n",
    "            \n",
    "            latents = latents + attn_output\n",
    "\n",
    "            for i in range(latents.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(latents[0, :, i, :])\n",
    "                plt.title('Skip Attn Output')\n",
    "                plt.show()\n",
    "                \n",
    "            lat = self.layernorm2(latents)  # (..., input_size, d_model)\n",
    "            ffn_output = self.ffn(lat)  # (..., input_size, d_model)\n",
    "            ffn_output = self.dropout2(ffn_output, training=True)\n",
    "            \n",
    "            latents = latents + ffn_output\n",
    "            \n",
    "            for i in range(latents.shape[2]):\n",
    "                plt.figure(figsize=(20, 3))\n",
    "                plt.plot(latents[0, :, i, :])\n",
    "                plt.title('Skip FFN Output')\n",
    "                plt.show()\n",
    "    else:\n",
    "        latents = self(latents)\n",
    "\n",
    "kinetic_energy_density = tf.reduce_sum(latents[..., 0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kinetic_energy_density[0] - target_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = None\n",
    "tensors = {}\n",
    "\n",
    "def plot_layer(layer):\n",
    "    global value, tensors\n",
    "    \n",
    "    if isinstance(layer, tf.keras.Model):\n",
    "        tree.traverse(plot_layer, layer.layers)\n",
    "\n",
    "    elif isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        value = sample_features[layer.name]\n",
    "        tensors[layer.output.name] = value\n",
    "        \n",
    "    elif isinstance(layer, tf.keras.layers.Layer):\n",
    "        if isinstance(layer.input, list):\n",
    "            value = layer([tensors[inp.name] for inp in layer.input])\n",
    "        else:\n",
    "            value = layer(tensors[layer.input.name])\n",
    "        tensors[layer.output.name] = value\n",
    "\n",
    "_ = tree.traverse(plot_layer, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, tensor in tensors.items():\n",
    "    if len(tensor.shape) == 3:\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(tensor[0])\n",
    "        plt.title(layer_name)\n",
    "        plt.show()\n",
    "    elif np.prod(tensor.shape) < 100:\n",
    "        print(layer_name, tensor)\n",
    "    else:\n",
    "        print(layer_name, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOnjoWzd/gc4HbCp8FvSubN",
   "collapsed_sections": [],
   "name": "train_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
